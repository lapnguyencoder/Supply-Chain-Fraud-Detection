{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "104cf72c56e943a1b04ed733e6de4195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a997b22fba840fcb485c24f6cc09d4a",
              "IPY_MODEL_7d69fbbddd7c42a99a3c823629c739ea",
              "IPY_MODEL_e2f6dc57fefd47bca7176997bd3ddb5d"
            ],
            "layout": "IPY_MODEL_048aacb7d9e649ca8acf650c2e242577"
          }
        },
        "8a997b22fba840fcb485c24f6cc09d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c0ec45ad244a51a05a2a060c4e1b55",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4ebd97c24348402fadc9d3d86093831c",
            "value": "Best‚Äátrial:‚Äá24.‚ÄáBest‚Äávalue:‚Äá3.91622:‚Äá100%"
          }
        },
        "7d69fbbddd7c42a99a3c823629c739ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7134dbe6445b40c4bb9dbe23469856b9",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39d26e0f89af4e039884cfe18e244728",
            "value": 50
          }
        },
        "e2f6dc57fefd47bca7176997bd3ddb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a87e605559419fafb65cad12cabb1c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_04948101d803408daa12fe366af848c6",
            "value": "‚Äá50/50‚Äá[00:38&lt;00:00,‚Äá‚Äá1.31it/s]"
          }
        },
        "048aacb7d9e649ca8acf650c2e242577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c0ec45ad244a51a05a2a060c4e1b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ebd97c24348402fadc9d3d86093831c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7134dbe6445b40c4bb9dbe23469856b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d26e0f89af4e039884cfe18e244728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59a87e605559419fafb65cad12cabb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04948101d803408daa12fe366af848c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "590cd96bccce4bdeab1bd225c3d8e27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59dce6dda5c447aab1c0ebf0d5eae191",
              "IPY_MODEL_c6bd6367ab8f4bda8b4304d012fff93d",
              "IPY_MODEL_641521c5d4974e668f190fbce89b091a"
            ],
            "layout": "IPY_MODEL_1cd9f57ac203427b96fbb5b33278990d"
          }
        },
        "59dce6dda5c447aab1c0ebf0d5eae191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82971eee21564cd1bf2d2b15ff3175c3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_64b5fc40b3524c3aa1b10681668cb313",
            "value": "Best‚Äátrial:‚Äá0.‚ÄáBest‚Äávalue:‚Äá1:‚Äá100%"
          }
        },
        "c6bd6367ab8f4bda8b4304d012fff93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b2b8267f8e41bf81af95a535786b7f",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6eef23a241444aa9b3fa3985e06307d",
            "value": 50
          }
        },
        "641521c5d4974e668f190fbce89b091a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d4d1f3f7384090a77ca91517195dda",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_486e1f46ca8d47ffa8865c7e1f948101",
            "value": "‚Äá50/50‚Äá[00:18&lt;00:00,‚Äá‚Äá3.30it/s]"
          }
        },
        "1cd9f57ac203427b96fbb5b33278990d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82971eee21564cd1bf2d2b15ff3175c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b5fc40b3524c3aa1b10681668cb313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1b2b8267f8e41bf81af95a535786b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6eef23a241444aa9b3fa3985e06307d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d4d1f3f7384090a77ca91517195dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486e1f46ca8d47ffa8865c7e1f948101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "104cf72c56e943a1b04ed733e6de4195",
            "8a997b22fba840fcb485c24f6cc09d4a",
            "7d69fbbddd7c42a99a3c823629c739ea",
            "e2f6dc57fefd47bca7176997bd3ddb5d",
            "048aacb7d9e649ca8acf650c2e242577",
            "23c0ec45ad244a51a05a2a060c4e1b55",
            "4ebd97c24348402fadc9d3d86093831c",
            "7134dbe6445b40c4bb9dbe23469856b9",
            "39d26e0f89af4e039884cfe18e244728",
            "59a87e605559419fafb65cad12cabb1c",
            "04948101d803408daa12fe366af848c6",
            "590cd96bccce4bdeab1bd225c3d8e27f",
            "59dce6dda5c447aab1c0ebf0d5eae191",
            "c6bd6367ab8f4bda8b4304d012fff93d",
            "641521c5d4974e668f190fbce89b091a",
            "1cd9f57ac203427b96fbb5b33278990d",
            "82971eee21564cd1bf2d2b15ff3175c3",
            "64b5fc40b3524c3aa1b10681668cb313",
            "b1b2b8267f8e41bf81af95a535786b7f",
            "c6eef23a241444aa9b3fa3985e06307d",
            "77d4d1f3f7384090a77ca91517195dda",
            "486e1f46ca8d47ffa8865c7e1f948101"
          ]
        },
        "id": "Tj4qVxJuDX4k",
        "outputId": "c5370b9b-9018-449b-f925-97383486ba7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• Using device: cuda\n",
            "GPU: Tesla T4\n",
            "Memory: 15.83 GB\n",
            "\n",
            "================================================================================\n",
            "üìä PHASE 1: DATA LOADING & EXPLORATION\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Dataset loaded successfully!\n",
            "üìà Shape: (2000, 22)\n",
            "üìù Columns: ['Type', 'Days for shipment (scheduled)', 'Category Name', 'Customer City', 'Customer Country', 'Customer Segment', 'Customer State', 'Department Name', 'Market', 'Order City', 'Order Country', 'Order Item Discount Rate', 'Order Item Quantity', 'Sales', 'Order Region', 'Order State', 'Product Name', 'Shipping Mode', 'Day of Week', 'Month', 'Year', 'Week of Year']\n",
            "\n",
            "üîç Data Types:\n",
            "Type                              object\n",
            "Days for shipment (scheduled)      int64\n",
            "Category Name                     object\n",
            "Customer City                     object\n",
            "Customer Country                  object\n",
            "Customer Segment                  object\n",
            "Customer State                    object\n",
            "Department Name                   object\n",
            "Market                            object\n",
            "Order City                        object\n",
            "Order Country                     object\n",
            "Order Item Discount Rate         float64\n",
            "Order Item Quantity                int64\n",
            "Sales                            float64\n",
            "Order Region                      object\n",
            "Order State                       object\n",
            "Product Name                      object\n",
            "Shipping Mode                     object\n",
            "Day of Week                        int64\n",
            "Month                              int64\n",
            "Year                               int64\n",
            "Week of Year                       int64\n",
            "dtype: object\n",
            "\n",
            "üìä Missing Values:\n",
            "Type                             0\n",
            "Days for shipment (scheduled)    0\n",
            "Category Name                    0\n",
            "Customer City                    0\n",
            "Customer Country                 0\n",
            "Customer Segment                 0\n",
            "Customer State                   0\n",
            "Department Name                  0\n",
            "Market                           0\n",
            "Order City                       0\n",
            "Order Country                    0\n",
            "Order Item Discount Rate         0\n",
            "Order Item Quantity              0\n",
            "Sales                            0\n",
            "Order Region                     0\n",
            "Order State                      0\n",
            "Product Name                     0\n",
            "Shipping Mode                    0\n",
            "Day of Week                      0\n",
            "Month                            0\n",
            "Year                             0\n",
            "Week of Year                     0\n",
            "dtype: int64\n",
            "\n",
            "================================================================================\n",
            "üîß PHASE 2: ADVANCED FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "‚è∞ Creating Temporal Features...\n",
            "‚úÖ Created 12 temporal features\n",
            "üë• Creating Behavioral Features...\n",
            "‚úÖ Created behavioral features\n",
            "üåç Creating Geographical Features...\n",
            "‚úÖ Created geographical features\n",
            "üí≥ Creating Payment & Risk Features...\n",
            "‚úÖ Fraud Risk Distribution:\n",
            "Fraud_Risk_Label\n",
            "0    1553\n",
            "1     447\n",
            "Name: count, dtype: int64\n",
            "   Fraud Rate: 22.35%\n",
            "üìä Creating Aggregation Features...\n",
            "‚úÖ Created aggregation features\n",
            "üîó Creating Interaction Features...\n",
            "‚úÖ Created interaction features\n",
            "üìÖ Creating Monthly Demand Target...\n",
            "‚úÖ Monthly demand aggregated\n",
            "   Unique Product-Region combinations: 314\n",
            "   Demand range: 1 - 59\n",
            "\n",
            "‚úÖ FEATURE ENGINEERING COMPLETE!\n",
            "üìä Final dataset shape: (2000, 79)\n",
            "\n",
            "================================================================================\n",
            "üî® PHASE 3: DATA PREPROCESSING & ENCODING\n",
            "================================================================================\n",
            "\n",
            "üè∑Ô∏è Encoding Categorical Variables...\n",
            "‚úÖ Encoded 13 categorical features\n",
            "üéØ Selecting Features for Modeling...\n",
            "‚úÖ Total features: 69\n",
            "   - Numerical: 56\n",
            "   - Encoded Categorical: 13\n",
            "üîç Handling Outliers...\n",
            "‚úÖ Outliers capped for 4 features\n",
            "üì¶ Preparing Datasets for Each Task...\n",
            "‚úÖ Dataset prepared:\n",
            "   - X shape: (2000, 69)\n",
            "   - y_demand shape: (2000,)\n",
            "   - y_fraud shape: (2000,)\n",
            "   - Fraud class distribution: [1553  447]\n",
            "\n",
            "================================================================================\n",
            "üìà PHASE 4: TASK 1 - DEMAND FORECASTING\n",
            "================================================================================\n",
            "\n",
            "Train set: (1600, 69), Test set: (400, 69)\n",
            "\n",
            "üå≤ Training Baseline: Random Forest Regressor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-30 13:38:14,934] A new study created in memory with name: no-name-730191af-c71f-435f-ad4f-90bba49a828c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Random Forest Results:\n",
            "   RMSE: 4.6847\n",
            "   MAE: 2.8165\n",
            "   R¬≤: 0.9313\n",
            "   MAPE: 36.0073%\n",
            "\n",
            "üöÄ Training Main Model: XGBoost with Optuna Tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "104cf72c56e943a1b04ed733e6de4195"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2026-01-30 13:38:15,844] Trial 0 finished with value: 4.4397989684636725 and parameters: {'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.22227824312530747, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'gamma': 0.02904180608409973, 'reg_alpha': 0.8661761457749352, 'reg_lambda': 0.6011150117432088}. Best is trial 0 with value: 4.4397989684636725.\n",
            "[I 2026-01-30 13:38:16,773] Trial 1 finished with value: 4.982779029118926 and parameters: {'n_estimators': 383, 'max_depth': 3, 'learning_rate': 0.29127385712697834, 'subsample': 0.9329770563201687, 'colsample_bytree': 0.6849356442713105, 'min_child_weight': 2, 'gamma': 0.09170225492671691, 'reg_alpha': 0.3042422429595377, 'reg_lambda': 0.5247564316322378}. Best is trial 0 with value: 4.4397989684636725.\n",
            "[I 2026-01-30 13:38:17,478] Trial 2 finished with value: 4.518241573027216 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.18743733946949004, 'subsample': 0.6557975442608167, 'colsample_bytree': 0.7168578594140873, 'min_child_weight': 4, 'gamma': 0.22803499210851796, 'reg_alpha': 0.7851759613930136, 'reg_lambda': 0.19967378215835974}. Best is trial 0 with value: 4.4397989684636725.\n",
            "[I 2026-01-30 13:38:18,708] Trial 3 finished with value: 3.9720456114471423 and parameters: {'n_estimators': 306, 'max_depth': 8, 'learning_rate': 0.02347061968879934, 'subsample': 0.8430179407605753, 'colsample_bytree': 0.6682096494749166, 'min_child_weight': 1, 'gamma': 0.4744427686266666, 'reg_alpha': 0.9656320330745594, 'reg_lambda': 0.8083973481164611}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:18,995] Trial 4 finished with value: 4.947157288218659 and parameters: {'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.2084275776885255, 'subsample': 0.7760609974958406, 'colsample_bytree': 0.6488152939379115, 'min_child_weight': 5, 'gamma': 0.017194260557609198, 'reg_alpha': 0.9093204020787821, 'reg_lambda': 0.2587799816000169}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:19,594] Trial 5 finished with value: 4.570056875530222 and parameters: {'n_estimators': 365, 'max_depth': 6, 'learning_rate': 0.16081972614156514, 'subsample': 0.8186841117373118, 'colsample_bytree': 0.6739417822102108, 'min_child_weight': 10, 'gamma': 0.3875664116805573, 'reg_alpha': 0.9394989415641891, 'reg_lambda': 0.8948273504276488}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:21,041] Trial 6 finished with value: 4.330669219916707 and parameters: {'n_estimators': 339, 'max_depth': 12, 'learning_rate': 0.03566282559505665, 'subsample': 0.6783931449676581, 'colsample_bytree': 0.6180909155642152, 'min_child_weight': 4, 'gamma': 0.194338644844741, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:21,618] Trial 7 finished with value: 4.5938581596668495 and parameters: {'n_estimators': 243, 'max_depth': 5, 'learning_rate': 0.16738186411589207, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'min_child_weight': 1, 'gamma': 0.49344346830025865, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 0.1987156815341724}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:21,971] Trial 8 finished with value: 4.054387369973518 and parameters: {'n_estimators': 102, 'max_depth': 11, 'learning_rate': 0.21498862971580895, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'gamma': 0.1792328642721363, 'reg_alpha': 0.11586905952512971, 'reg_lambda': 0.8631034258755935}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:22,649] Trial 9 finished with value: 4.326051511446379 and parameters: {'n_estimators': 349, 'max_depth': 6, 'learning_rate': 0.028431921582946856, 'subsample': 0.7243929286862649, 'colsample_bytree': 0.7300733288106989, 'min_child_weight': 8, 'gamma': 0.31877873567760656, 'reg_alpha': 0.8872127425763265, 'reg_lambda': 0.4722149251619493}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:23,327] Trial 10 finished with value: 4.039230608808169 and parameters: {'n_estimators': 478, 'max_depth': 9, 'learning_rate': 0.08408017388374428, 'subsample': 0.9729161367647149, 'colsample_bytree': 0.8076576013037925, 'min_child_weight': 7, 'gamma': 0.4865417857436737, 'reg_alpha': 0.599915636812576, 'reg_lambda': 0.6579621849710365}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:24,040] Trial 11 finished with value: 4.019275950043447 and parameters: {'n_estimators': 499, 'max_depth': 9, 'learning_rate': 0.082001198725237, 'subsample': 0.9848647216726907, 'colsample_bytree': 0.8236086130224007, 'min_child_weight': 7, 'gamma': 0.48406656813731264, 'reg_alpha': 0.5742694052768438, 'reg_lambda': 0.6936028059731288}. Best is trial 3 with value: 3.9720456114471423.\n",
            "[I 2026-01-30 13:38:24,683] Trial 12 finished with value: 3.9251029420218715 and parameters: {'n_estimators': 476, 'max_depth': 9, 'learning_rate': 0.09608884030889052, 'subsample': 0.9988902865705865, 'colsample_bytree': 0.8005270694249143, 'min_child_weight': 7, 'gamma': 0.3859620061900356, 'reg_alpha': 0.5627560184469953, 'reg_lambda': 0.9913941814623418}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:25,410] Trial 13 finished with value: 4.1066402720143955 and parameters: {'n_estimators': 434, 'max_depth': 9, 'learning_rate': 0.09894068394129425, 'subsample': 0.8923645209213664, 'colsample_bytree': 0.7641701227757287, 'min_child_weight': 9, 'gamma': 0.3931114877464755, 'reg_alpha': 0.40095596968204394, 'reg_lambda': 0.9989361297089024}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:25,869] Trial 14 finished with value: 4.244356784503413 and parameters: {'n_estimators': 163, 'max_depth': 8, 'learning_rate': 0.11467341000677357, 'subsample': 0.7608080041034748, 'colsample_bytree': 0.997189099496398, 'min_child_weight': 6, 'gamma': 0.3931376241200326, 'reg_alpha': 0.6891558229848622, 'reg_lambda': 0.7661828485483133}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:27,414] Trial 15 finished with value: 4.318557023900085 and parameters: {'n_estimators': 429, 'max_depth': 10, 'learning_rate': 0.010584319458814986, 'subsample': 0.6043956756975085, 'colsample_bytree': 0.8561711433906498, 'min_child_weight': 4, 'gamma': 0.318664798845569, 'reg_alpha': 0.015510381994227218, 'reg_lambda': 0.977266465595078}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:28,121] Trial 16 finished with value: 4.093842483524155 and parameters: {'n_estimators': 307, 'max_depth': 7, 'learning_rate': 0.061166634948781745, 'subsample': 0.8693087163058641, 'colsample_bytree': 0.7615454572554384, 'min_child_weight': 6, 'gamma': 0.31814390103226703, 'reg_alpha': 0.4375533835139923, 'reg_lambda': 0.013179214380923454}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:28,475] Trial 17 finished with value: 4.203518873854566 and parameters: {'n_estimators': 185, 'max_depth': 8, 'learning_rate': 0.1348311040420471, 'subsample': 0.9396690699855346, 'colsample_bytree': 0.875869770084707, 'min_child_weight': 3, 'gamma': 0.4252563081779611, 'reg_alpha': 0.999409973983931, 'reg_lambda': 0.7734886723146674}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:29,327] Trial 18 finished with value: 4.130818049808067 and parameters: {'n_estimators': 440, 'max_depth': 10, 'learning_rate': 0.055813474773975594, 'subsample': 0.9441261598301947, 'colsample_bytree': 0.6077502042717192, 'min_child_weight': 8, 'gamma': 0.4368355178313592, 'reg_alpha': 0.6800849793217775, 'reg_lambda': 0.3992946483188063}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:29,870] Trial 19 finished with value: 4.057284014412646 and parameters: {'n_estimators': 389, 'max_depth': 7, 'learning_rate': 0.12628020891915231, 'subsample': 0.9965108784574399, 'colsample_bytree': 0.7722533855765749, 'min_child_weight': 5, 'gamma': 0.2815024159734312, 'reg_alpha': 0.4875531490645628, 'reg_lambda': 0.9296737575012058}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:30,844] Trial 20 finished with value: 4.30073202245328 and parameters: {'n_estimators': 311, 'max_depth': 11, 'learning_rate': 0.054875761504527165, 'subsample': 0.8499529023421235, 'colsample_bytree': 0.7114319649640095, 'min_child_weight': 10, 'gamma': 0.3490483200027007, 'reg_alpha': 0.20882156612896802, 'reg_lambda': 0.7167190764009185}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:31,520] Trial 21 finished with value: 3.944344037230171 and parameters: {'n_estimators': 474, 'max_depth': 9, 'learning_rate': 0.08242314773446581, 'subsample': 0.9961016149557428, 'colsample_bytree': 0.820565213150656, 'min_child_weight': 7, 'gamma': 0.4456502988121036, 'reg_alpha': 0.5723095050235898, 'reg_lambda': 0.6521949065141551}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:32,394] Trial 22 finished with value: 4.0086178927753044 and parameters: {'n_estimators': 470, 'max_depth': 10, 'learning_rate': 0.08834045961601897, 'subsample': 0.9143621935916726, 'colsample_bytree': 0.8391376116038478, 'min_child_weight': 7, 'gamma': 0.43539356532401174, 'reg_alpha': 0.5617268053898847, 'reg_lambda': 0.8237731195819505}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:33,675] Trial 23 finished with value: 4.0827215605753135 and parameters: {'n_estimators': 410, 'max_depth': 8, 'learning_rate': 0.019450432561341748, 'subsample': 0.964140312469197, 'colsample_bytree': 0.7869861752770332, 'min_child_weight': 8, 'gamma': 0.4513628454626619, 'reg_alpha': 0.34945686485957217, 'reg_lambda': 0.5865765216928052}. Best is trial 12 with value: 3.9251029420218715.\n",
            "[I 2026-01-30 13:38:34,533] Trial 24 finished with value: 3.91622225627697 and parameters: {'n_estimators': 468, 'max_depth': 9, 'learning_rate': 0.06161168774082956, 'subsample': 0.9972721552920446, 'colsample_bytree': 0.8929079975297753, 'min_child_weight': 6, 'gamma': 0.3601378235855471, 'reg_alpha': 0.6744524411267624, 'reg_lambda': 0.919603310407603}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:35,177] Trial 25 finished with value: 3.9816068719903845 and parameters: {'n_estimators': 466, 'max_depth': 9, 'learning_rate': 0.10648575680484346, 'subsample': 0.9860583690024798, 'colsample_bytree': 0.9398770580467641, 'min_child_weight': 6, 'gamma': 0.3620170377562622, 'reg_alpha': 0.7194627354179683, 'reg_lambda': 0.9187525586847577}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:35,870] Trial 26 finished with value: 4.308358013935833 and parameters: {'n_estimators': 495, 'max_depth': 11, 'learning_rate': 0.1455240439346625, 'subsample': 0.9587438349696294, 'colsample_bytree': 0.8813495478000508, 'min_child_weight': 9, 'gamma': 0.2710643501932481, 'reg_alpha': 0.6298615240216888, 'reg_lambda': 0.357760435903419}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:36,747] Trial 27 finished with value: 4.029091900536491 and parameters: {'n_estimators': 453, 'max_depth': 10, 'learning_rate': 0.06315760113354547, 'subsample': 0.9116131329133695, 'colsample_bytree': 0.9704647216315219, 'min_child_weight': 7, 'gamma': 0.3600631573608326, 'reg_alpha': 0.5017557161070063, 'reg_lambda': 0.9719192920379199}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:37,629] Trial 28 finished with value: 4.313930992766523 and parameters: {'n_estimators': 418, 'max_depth': 7, 'learning_rate': 0.04478209189599574, 'subsample': 0.9182889090652587, 'colsample_bytree': 0.8592766437492362, 'min_child_weight': 5, 'gamma': 0.40758316189150745, 'reg_alpha': 0.5112151470010984, 'reg_lambda': 0.6343522356461359}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:38,157] Trial 29 finished with value: 4.435481512343151 and parameters: {'n_estimators': 387, 'max_depth': 12, 'learning_rate': 0.24598412021593608, 'subsample': 0.9975189864325604, 'colsample_bytree': 0.8097225151582518, 'min_child_weight': 9, 'gamma': 0.12590071115354062, 'reg_alpha': 0.7962360862400143, 'reg_lambda': 0.5766472380381535}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:38,870] Trial 30 finished with value: 4.065752810581092 and parameters: {'n_estimators': 407, 'max_depth': 9, 'learning_rate': 0.07473739724276562, 'subsample': 0.9560926335881872, 'colsample_bytree': 0.884896350219194, 'min_child_weight': 6, 'gamma': 0.2941694213444297, 'reg_alpha': 0.8273979909527545, 'reg_lambda': 0.895931665569789}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:39,875] Trial 31 finished with value: 4.1133320253721495 and parameters: {'n_estimators': 456, 'max_depth': 8, 'learning_rate': 0.038749026666885567, 'subsample': 0.8221936511251956, 'colsample_bytree': 0.7421548856945066, 'min_child_weight': 3, 'gamma': 0.45402949346103977, 'reg_alpha': 0.6517250323160249, 'reg_lambda': 0.7712560045523109}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:40,595] Trial 32 finished with value: 4.301866773769013 and parameters: {'n_estimators': 499, 'max_depth': 8, 'learning_rate': 0.10998827058740158, 'subsample': 0.867741310131008, 'colsample_bytree': 0.8327977177871486, 'min_child_weight': 7, 'gamma': 0.46095282629733214, 'reg_alpha': 0.4273102406197883, 'reg_lambda': 0.8242786076827361}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:41,223] Trial 33 finished with value: 4.209482822863912 and parameters: {'n_estimators': 275, 'max_depth': 9, 'learning_rate': 0.07107572627735981, 'subsample': 0.9412654627584197, 'colsample_bytree': 0.7000963164567776, 'min_child_weight': 8, 'gamma': 0.4135289951982787, 'reg_alpha': 0.7389620005610922, 'reg_lambda': 0.9311189354957644}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:42,467] Trial 34 finished with value: 4.256562271650272 and parameters: {'n_estimators': 335, 'max_depth': 10, 'learning_rate': 0.012012358149628305, 'subsample': 0.7450024963669857, 'colsample_bytree': 0.6387292437484665, 'min_child_weight': 3, 'gamma': 0.3689818375153101, 'reg_alpha': 0.8408387164493896, 'reg_lambda': 0.7386016254599277}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:43,265] Trial 35 finished with value: 4.256067096740606 and parameters: {'n_estimators': 373, 'max_depth': 6, 'learning_rate': 0.04265853022030246, 'subsample': 0.790326396247475, 'colsample_bytree': 0.79537739545163, 'min_child_weight': 2, 'gamma': 0.3413605962522464, 'reg_alpha': 0.9761490656991632, 'reg_lambda': 0.8564043251288442}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:43,563] Trial 36 finished with value: 4.237882055653148 and parameters: {'n_estimators': 215, 'max_depth': 7, 'learning_rate': 0.29415512870581484, 'subsample': 0.9740034141102191, 'colsample_bytree': 0.907280164592475, 'min_child_weight': 5, 'gamma': 0.4674929794077333, 'reg_alpha': 0.554842727632132, 'reg_lambda': 0.4943524288495632}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:44,239] Trial 37 finished with value: 4.581418463925945 and parameters: {'n_estimators': 447, 'max_depth': 4, 'learning_rate': 0.18345038225394097, 'subsample': 0.997758548030039, 'colsample_bytree': 0.7484639117160921, 'min_child_weight': 6, 'gamma': 0.05328191267652069, 'reg_alpha': 0.35418898807812327, 'reg_lambda': 0.6685716096261274}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:44,828] Trial 38 finished with value: 4.538239448763311 and parameters: {'n_estimators': 282, 'max_depth': 8, 'learning_rate': 0.2686964766836592, 'subsample': 0.7195331111227535, 'colsample_bytree': 0.6832147514638646, 'min_child_weight': 4, 'gamma': 0.2353861801274104, 'reg_alpha': 0.6185886586933449, 'reg_lambda': 0.8090474074105809}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:46,395] Trial 39 finished with value: 4.065880176180265 and parameters: {'n_estimators': 476, 'max_depth': 11, 'learning_rate': 0.027432484170702424, 'subsample': 0.8925943219752998, 'colsample_bytree': 0.6577110784026389, 'min_child_weight': 2, 'gamma': 0.3801764051416484, 'reg_alpha': 0.9144174942523169, 'reg_lambda': 0.555087349387004}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:46,704] Trial 40 finished with value: 4.074265096662324 and parameters: {'n_estimators': 104, 'max_depth': 9, 'learning_rate': 0.1298542942082374, 'subsample': 0.9216927732725614, 'colsample_bytree': 0.7869622885817156, 'min_child_weight': 5, 'gamma': 0.41401159198548115, 'reg_alpha': 0.7513403814811302, 'reg_lambda': 0.8694383399948531}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:47,343] Trial 41 finished with value: 3.9327210989732757 and parameters: {'n_estimators': 473, 'max_depth': 9, 'learning_rate': 0.10215009389888088, 'subsample': 0.9747534666488381, 'colsample_bytree': 0.991499957605356, 'min_child_weight': 6, 'gamma': 0.4905487582297645, 'reg_alpha': 0.705391089466973, 'reg_lambda': 0.9200181507533081}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:48,038] Trial 42 finished with value: 4.027104575069403 and parameters: {'n_estimators': 481, 'max_depth': 10, 'learning_rate': 0.09094759937341382, 'subsample': 0.9693879095108486, 'colsample_bytree': 0.946921879348143, 'min_child_weight': 7, 'gamma': 0.48618941280306033, 'reg_alpha': 0.6887253227283779, 'reg_lambda': 0.9552801919609046}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:48,624] Trial 43 finished with value: 4.042483034304733 and parameters: {'n_estimators': 404, 'max_depth': 9, 'learning_rate': 0.09845551139650516, 'subsample': 0.9788301772205945, 'colsample_bytree': 0.9884997762149383, 'min_child_weight': 6, 'gamma': 0.49855853472221034, 'reg_alpha': 0.5244630961257306, 'reg_lambda': 0.881347499287641}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:49,341] Trial 44 finished with value: 4.061551027234075 and parameters: {'n_estimators': 427, 'max_depth': 8, 'learning_rate': 0.07213395010205571, 'subsample': 0.9522223345801327, 'colsample_bytree': 0.9619849235628292, 'min_child_weight': 7, 'gamma': 0.4387125149829939, 'reg_alpha': 0.46449610997748586, 'reg_lambda': 0.8074479873050904}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:49,737] Trial 45 finished with value: 4.0867725343251555 and parameters: {'n_estimators': 249, 'max_depth': 9, 'learning_rate': 0.15329985869641477, 'subsample': 0.9998461347430196, 'colsample_bytree': 0.9185754109686747, 'min_child_weight': 8, 'gamma': 0.47007688024825783, 'reg_alpha': 0.6019526023487327, 'reg_lambda': 0.9306528122971963}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:50,251] Trial 46 finished with value: 4.090554657426729 and parameters: {'n_estimators': 355, 'max_depth': 7, 'learning_rate': 0.12150756159965069, 'subsample': 0.9273694879500421, 'colsample_bytree': 0.815742850617034, 'min_child_weight': 1, 'gamma': 0.393087528062488, 'reg_alpha': 0.7851258737025892, 'reg_lambda': 0.9781858791650158}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:51,310] Trial 47 finished with value: 4.128068880541496 and parameters: {'n_estimators': 488, 'max_depth': 10, 'learning_rate': 0.05201010609239824, 'subsample': 0.8252523496757214, 'colsample_bytree': 0.8600671892103194, 'min_child_weight': 6, 'gamma': 0.33296071806388566, 'reg_alpha': 0.9471701927170987, 'reg_lambda': 0.6338607771666376}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:52,607] Trial 48 finished with value: 4.2138960429559535 and parameters: {'n_estimators': 451, 'max_depth': 8, 'learning_rate': 0.024951826982454912, 'subsample': 0.6752502540594851, 'colsample_bytree': 0.8415261962881877, 'min_child_weight': 4, 'gamma': 0.47748694800188773, 'reg_alpha': 0.6718707763535728, 'reg_lambda': 0.7314593398805278}. Best is trial 24 with value: 3.91622225627697.\n",
            "[I 2026-01-30 13:38:53,073] Trial 49 finished with value: 4.273226382325141 and parameters: {'n_estimators': 329, 'max_depth': 5, 'learning_rate': 0.1682132028364634, 'subsample': 0.9803336402859292, 'colsample_bytree': 0.9004838433789619, 'min_child_weight': 7, 'gamma': 0.4975396224170124, 'reg_alpha': 0.860948064513512, 'reg_lambda': 0.9910253283664451}. Best is trial 24 with value: 3.91622225627697.\n",
            "\n",
            "üèÜ Best XGBoost parameters:\n",
            "{'n_estimators': 468, 'max_depth': 9, 'learning_rate': 0.06161168774082956, 'subsample': 0.9972721552920446, 'colsample_bytree': 0.8929079975297753, 'min_child_weight': 6, 'gamma': 0.3601378235855471, 'reg_alpha': 0.6744524411267624, 'reg_lambda': 0.919603310407603}\n",
            "\n",
            "‚úÖ XGBoost Results:\n",
            "   RMSE: 3.9162\n",
            "   MAE: 2.2919\n",
            "   R¬≤: 0.9520\n",
            "   MAPE: 29.8755%\n",
            "\n",
            "üí° Training Advanced Model: LightGBM...\n",
            "‚úÖ LightGBM Results:\n",
            "   RMSE: 4.5040\n",
            "   MAE: 2.6689\n",
            "   R¬≤: 0.9365\n",
            "   MAPE: 31.9147%\n",
            "\n",
            "üìä DEMAND FORECASTING SUMMARY:\n",
            "============================================================\n",
            "                   RMSE       MAE        R2       MAPE\n",
            "Random Forest  4.684671  2.816544  0.931345  36.007257\n",
            "XGBoost        3.916222  2.291927  0.952021  29.875542\n",
            "LightGBM       4.503962  2.668902  0.936539  31.914721\n",
            "============================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üîí PHASE 5: TASK 2 - FRAUD RISK CLASSIFICATION\n",
            "================================================================================\n",
            "\n",
            "Train set: (1600, 69), Test set: (400, 69)\n",
            "Train fraud rate: 22.38%\n",
            "Test fraud rate: 22.25%\n",
            "\n",
            "‚öñÔ∏è Handling Class Imbalance with SMOTE...\n",
            "After SMOTE: (2484, 69)\n",
            "Class distribution: [1242 1242]\n",
            "\n",
            "üìä Training Baseline: Logistic Regression...\n",
            "‚úÖ Logistic Regression Results:\n",
            "   ROC-AUC: 1.0000\n",
            "   Avg Precision: 1.0000\n",
            "   F1-Score: 0.9944\n",
            "   Accuracy: 0.9975\n",
            "\n",
            "üå≤ Training Main Model: Random Forest Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-30 13:38:55,447] A new study created in memory with name: no-name-6b23165e-0a33-4c84-83ac-cf465d619f57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Random Forest Results:\n",
            "   ROC-AUC: 1.0000\n",
            "   Avg Precision: 1.0000\n",
            "   F1-Score: 1.0000\n",
            "   Accuracy: 1.0000\n",
            "\n",
            "üöÄ Training Advanced Model: XGBoost Classifier...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "590cd96bccce4bdeab1bd225c3d8e27f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2026-01-30 13:38:55,796] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.22227824312530747, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'gamma': 0.02904180608409973, 'reg_alpha': 0.8661761457749352, 'reg_lambda': 0.6011150117432088}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:56,239] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 383, 'max_depth': 3, 'learning_rate': 0.29127385712697834, 'subsample': 0.9329770563201687, 'colsample_bytree': 0.6849356442713105, 'min_child_weight': 2, 'gamma': 0.09170225492671691, 'reg_alpha': 0.3042422429595377, 'reg_lambda': 0.5247564316322378}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:56,638] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.18743733946949004, 'subsample': 0.6557975442608167, 'colsample_bytree': 0.7168578594140873, 'min_child_weight': 4, 'gamma': 0.22803499210851796, 'reg_alpha': 0.7851759613930136, 'reg_lambda': 0.19967378215835974}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:57,229] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 306, 'max_depth': 8, 'learning_rate': 0.02347061968879934, 'subsample': 0.8430179407605753, 'colsample_bytree': 0.6682096494749166, 'min_child_weight': 1, 'gamma': 0.4744427686266666, 'reg_alpha': 0.9656320330745594, 'reg_lambda': 0.8083973481164611}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:57,560] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.2084275776885255, 'subsample': 0.7760609974958406, 'colsample_bytree': 0.6488152939379115, 'min_child_weight': 5, 'gamma': 0.017194260557609198, 'reg_alpha': 0.9093204020787821, 'reg_lambda': 0.2587799816000169}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:58,179] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 365, 'max_depth': 6, 'learning_rate': 0.16081972614156514, 'subsample': 0.8186841117373118, 'colsample_bytree': 0.6739417822102108, 'min_child_weight': 10, 'gamma': 0.3875664116805573, 'reg_alpha': 0.9394989415641891, 'reg_lambda': 0.8948273504276488}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:58,647] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 339, 'max_depth': 12, 'learning_rate': 0.03566282559505665, 'subsample': 0.6783931449676581, 'colsample_bytree': 0.6180909155642152, 'min_child_weight': 4, 'gamma': 0.194338644844741, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:58,928] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 243, 'max_depth': 5, 'learning_rate': 0.16738186411589207, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'min_child_weight': 1, 'gamma': 0.49344346830025865, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 0.1987156815341724}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:59,067] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 102, 'max_depth': 11, 'learning_rate': 0.21498862971580895, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'gamma': 0.1792328642721363, 'reg_alpha': 0.11586905952512971, 'reg_lambda': 0.8631034258755935}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:59,469] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 349, 'max_depth': 6, 'learning_rate': 0.028431921582946856, 'subsample': 0.7243929286862649, 'colsample_bytree': 0.7300733288106989, 'min_child_weight': 8, 'gamma': 0.31877873567760656, 'reg_alpha': 0.8872127425763265, 'reg_lambda': 0.4722149251619493}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:38:59,945] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 478, 'max_depth': 10, 'learning_rate': 0.09923132132057606, 'subsample': 0.9729161367647149, 'colsample_bytree': 0.8085360047450806, 'min_child_weight': 7, 'gamma': 0.007572118551378439, 'reg_alpha': 0.6233765186294654, 'reg_lambda': 0.5705478648816833}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:00,362] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 432, 'max_depth': 9, 'learning_rate': 0.2904369127224858, 'subsample': 0.9481474318740984, 'colsample_bytree': 0.7971457481268197, 'min_child_weight': 3, 'gamma': 0.11154745319128073, 'reg_alpha': 0.3999340127675681, 'reg_lambda': 0.5602497503032242}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:00,567] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 178, 'max_depth': 3, 'learning_rate': 0.2874157519953743, 'subsample': 0.8884170683398009, 'colsample_bytree': 0.7874820875551369, 'min_child_weight': 3, 'gamma': 0.1237120888013009, 'reg_alpha': 0.5097397989010394, 'reg_lambda': 0.420331699674971}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:01,015] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 434, 'max_depth': 12, 'learning_rate': 0.2463761513207155, 'subsample': 0.9997449754566206, 'colsample_bytree': 0.6021809558214185, 'min_child_weight': 2, 'gamma': 0.08870853894513074, 'reg_alpha': 0.17057827940885525, 'reg_lambda': 0.6855046081289342}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:01,223] Trial 14 finished with value: 0.9999999999999999 and parameters: {'n_estimators': 163, 'max_depth': 8, 'learning_rate': 0.25197495382971413, 'subsample': 0.9115356811308601, 'colsample_bytree': 0.7337344348736515, 'min_child_weight': 6, 'gamma': 0.03627773204447675, 'reg_alpha': 0.3571513799574839, 'reg_lambda': 0.36340653237477843}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:01,633] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 402, 'max_depth': 10, 'learning_rate': 0.2496743209156137, 'subsample': 0.7634072550781038, 'colsample_bytree': 0.857356555876742, 'min_child_weight': 3, 'gamma': 0.2924604677532988, 'reg_alpha': 0.015510381994227218, 'reg_lambda': 0.6696242694360999}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:01,981] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 298, 'max_depth': 4, 'learning_rate': 0.10830466826583755, 'subsample': 0.8503991699305873, 'colsample_bytree': 0.7019847524469807, 'min_child_weight': 2, 'gamma': 0.08000054778458476, 'reg_alpha': 0.591628941408769, 'reg_lambda': 0.013179214380923454}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:02,473] Trial 17 finished with value: 1.0 and parameters: {'n_estimators': 488, 'max_depth': 7, 'learning_rate': 0.2927221426237945, 'subsample': 0.9340956836065549, 'colsample_bytree': 0.7694004784138841, 'min_child_weight': 5, 'gamma': 0.1601698676289583, 'reg_alpha': 0.7370095621276695, 'reg_lambda': 0.9910985934143602}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:02,746] Trial 18 finished with value: 1.0 and parameters: {'n_estimators': 214, 'max_depth': 9, 'learning_rate': 0.11932883152224968, 'subsample': 0.6026168324121943, 'colsample_bytree': 0.8416634198004798, 'min_child_weight': 2, 'gamma': 0.0553617064887679, 'reg_alpha': 0.4480047581616442, 'reg_lambda': 0.68046811494275}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:03,155] Trial 19 finished with value: 1.0 and parameters: {'n_estimators': 389, 'max_depth': 7, 'learning_rate': 0.2200408385374071, 'subsample': 0.858058025655211, 'colsample_bytree': 0.6296618535752111, 'min_child_weight': 9, 'gamma': 0.26226212705991964, 'reg_alpha': 0.27054184427552774, 'reg_lambda': 0.3337958867866851}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:03,501] Trial 20 finished with value: 1.0 and parameters: {'n_estimators': 299, 'max_depth': 4, 'learning_rate': 0.2634166119899526, 'subsample': 0.8048690303422982, 'colsample_bytree': 0.9780383022354938, 'min_child_weight': 4, 'gamma': 0.13841134390660553, 'reg_alpha': 0.6109419986889795, 'reg_lambda': 0.5935992583320445}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:03,808] Trial 21 finished with value: 1.0 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.18590675962516554, 'subsample': 0.7055818053995003, 'colsample_bytree': 0.7130366546802294, 'min_child_weight': 4, 'gamma': 0.20959715840032464, 'reg_alpha': 0.7948546007429274, 'reg_lambda': 0.09443665865179543}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:04,102] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 248, 'max_depth': 4, 'learning_rate': 0.13629258043835277, 'subsample': 0.7488306146704025, 'colsample_bytree': 0.6893181261975687, 'min_child_weight': 3, 'gamma': 0.35031122233487466, 'reg_alpha': 0.7020014768886059, 'reg_lambda': 0.4844455435364333}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:04,453] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 325, 'max_depth': 3, 'learning_rate': 0.20374432418292454, 'subsample': 0.6073248792362046, 'colsample_bytree': 0.7512970916485808, 'min_child_weight': 2, 'gamma': 0.2321458999707593, 'reg_alpha': 0.8183944068729494, 'reg_lambda': 0.24351001160119412}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:04,694] Trial 24 finished with value: 1.0 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.18167251084015104, 'subsample': 0.6512724702232536, 'colsample_bytree': 0.6568950498440635, 'min_child_weight': 6, 'gamma': 0.06776145263951469, 'reg_alpha': 0.5253625555394762, 'reg_lambda': 0.3711474026033982}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:05,024] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.23345283903906056, 'subsample': 0.8716844621710428, 'colsample_bytree': 0.701870398920289, 'min_child_weight': 4, 'gamma': 0.44147705466886755, 'reg_alpha': 0.8533012648195032, 'reg_lambda': 0.09529338890229265}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:05,212] Trial 26 finished with value: 1.0 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.27195170862190743, 'subsample': 0.8295815448711918, 'colsample_bytree': 0.6390144737460547, 'min_child_weight': 2, 'gamma': 0.002962640518382284, 'reg_alpha': 0.7063801435187724, 'reg_lambda': 0.7361099818934926}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:05,645] Trial 27 finished with value: 1.0 and parameters: {'n_estimators': 380, 'max_depth': 3, 'learning_rate': 0.05921440694656077, 'subsample': 0.7862901903405964, 'colsample_bytree': 0.7488621218277184, 'min_child_weight': 5, 'gamma': 0.27148295870626415, 'reg_alpha': 0.9895420764074496, 'reg_lambda': 0.6094934702074952}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:05,975] Trial 28 finished with value: 1.0 and parameters: {'n_estimators': 266, 'max_depth': 11, 'learning_rate': 0.18775249117712542, 'subsample': 0.9228113692867211, 'colsample_bytree': 0.6805505706097182, 'min_child_weight': 1, 'gamma': 0.15885388716829596, 'reg_alpha': 0.26605512260357317, 'reg_lambda': 0.43951041122886425}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:06,354] Trial 29 finished with value: 1.0 and parameters: {'n_estimators': 318, 'max_depth': 8, 'learning_rate': 0.1467298698673201, 'subsample': 0.9800957308963963, 'colsample_bytree': 0.66594978983778, 'min_child_weight': 1, 'gamma': 0.10002707383307419, 'reg_alpha': 0.3264269050424323, 'reg_lambda': 0.2965607932835296}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:06,782] Trial 30 finished with value: 1.0 and parameters: {'n_estimators': 415, 'max_depth': 5, 'learning_rate': 0.23184620679410226, 'subsample': 0.7340508610504259, 'colsample_bytree': 0.6009230104184364, 'min_child_weight': 3, 'gamma': 0.04278475353216233, 'reg_alpha': 0.20008006048696825, 'reg_lambda': 0.7590842160996372}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:07,101] Trial 31 finished with value: 1.0 and parameters: {'n_estimators': 236, 'max_depth': 9, 'learning_rate': 0.08901856086288336, 'subsample': 0.8375673911058672, 'colsample_bytree': 0.647393749185171, 'min_child_weight': 1, 'gamma': 0.39938939499176074, 'reg_alpha': 0.9790219644125757, 'reg_lambda': 0.5159958792219147}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:07,384] Trial 32 finished with value: 1.0 and parameters: {'n_estimators': 212, 'max_depth': 7, 'learning_rate': 0.07623720661751193, 'subsample': 0.7965463627014362, 'colsample_bytree': 0.6756877771165838, 'min_child_weight': 2, 'gamma': 0.4902949276047849, 'reg_alpha': 0.9007308511439244, 'reg_lambda': 0.9907458665061294}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:07,767] Trial 33 finished with value: 0.9999999999999999 and parameters: {'n_estimators': 361, 'max_depth': 6, 'learning_rate': 0.13029197983037064, 'subsample': 0.8843190881003888, 'colsample_bytree': 0.7202324585461473, 'min_child_weight': 5, 'gamma': 0.34897343048709784, 'reg_alpha': 0.9022411600789249, 'reg_lambda': 0.8084090109264674}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:08,135] Trial 34 finished with value: 1.0 and parameters: {'n_estimators': 314, 'max_depth': 11, 'learning_rate': 0.1629703083037651, 'subsample': 0.8190445679231486, 'colsample_bytree': 0.6276136571831136, 'min_child_weight': 1, 'gamma': 0.22451561782298673, 'reg_alpha': 0.9405025549030869, 'reg_lambda': 0.9118542471940665}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:08,453] Trial 35 finished with value: 1.0 and parameters: {'n_estimators': 290, 'max_depth': 12, 'learning_rate': 0.2007262645443962, 'subsample': 0.7741645444647017, 'colsample_bytree': 0.6556360654745068, 'min_child_weight': 3, 'gamma': 0.4240899139170608, 'reg_alpha': 0.8201924643089689, 'reg_lambda': 0.9099933852714384}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:08,962] Trial 36 finished with value: 1.0 and parameters: {'n_estimators': 340, 'max_depth': 10, 'learning_rate': 0.04393524107658403, 'subsample': 0.694338834099599, 'colsample_bytree': 0.6875943380135292, 'min_child_weight': 2, 'gamma': 0.18007471792052143, 'reg_alpha': 0.7493530757946315, 'reg_lambda': 0.16609836873747524}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:09,462] Trial 37 finished with value: 1.0 and parameters: {'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.018945602500785187, 'subsample': 0.6414109605820983, 'colsample_bytree': 0.7582904913624, 'min_child_weight': 4, 'gamma': 0.32765101491017595, 'reg_alpha': 0.6741056392503517, 'reg_lambda': 0.7826447982213577}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:10,190] Trial 38 finished with value: 1.0 and parameters: {'n_estimators': 449, 'max_depth': 8, 'learning_rate': 0.17282717826550917, 'subsample': 0.904688600178765, 'colsample_bytree': 0.621663737839185, 'min_child_weight': 1, 'gamma': 0.45238163459490055, 'reg_alpha': 0.8568376769895517, 'reg_lambda': 0.6410376393989731}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:10,696] Trial 39 finished with value: 1.0 and parameters: {'n_estimators': 364, 'max_depth': 6, 'learning_rate': 0.2704862696882017, 'subsample': 0.9458829506563314, 'colsample_bytree': 0.8247641928574576, 'min_child_weight': 1, 'gamma': 0.028207187440150466, 'reg_alpha': 0.947137906732765, 'reg_lambda': 0.5557471959467853}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:10,933] Trial 40 finished with value: 1.0 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.15054354387123212, 'subsample': 0.8564381057543136, 'colsample_bytree': 0.7365843039252995, 'min_child_weight': 7, 'gamma': 0.1457688572978664, 'reg_alpha': 0.06162031740579063, 'reg_lambda': 0.7257445116590928}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:11,198] Trial 41 finished with value: 1.0 and parameters: {'n_estimators': 226, 'max_depth': 3, 'learning_rate': 0.21259253639805734, 'subsample': 0.6763025298115524, 'colsample_bytree': 0.6627347900135979, 'min_child_weight': 6, 'gamma': 0.025693110702804327, 'reg_alpha': 0.9115643828941914, 'reg_lambda': 0.24797950004849703}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:11,411] Trial 42 finished with value: 1.0 and parameters: {'n_estimators': 144, 'max_depth': 5, 'learning_rate': 0.23146770240776593, 'subsample': 0.8080684433645796, 'colsample_bytree': 0.6971511938015964, 'min_child_weight': 10, 'gamma': 0.11619009512748196, 'reg_alpha': 0.8532245951708677, 'reg_lambda': 0.4051516529605818}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:11,715] Trial 43 finished with value: 1.0 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.19551615039039327, 'subsample': 0.6270147255078318, 'colsample_bytree': 0.6398538218149827, 'min_child_weight': 7, 'gamma': 0.011160785363225012, 'reg_alpha': 0.9636747525708342, 'reg_lambda': 0.17798016662816077}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:11,992] Trial 44 finished with value: 1.0 and parameters: {'n_estimators': 228, 'max_depth': 4, 'learning_rate': 0.16653436480433018, 'subsample': 0.7604324091183771, 'colsample_bytree': 0.7127611342766016, 'min_child_weight': 4, 'gamma': 0.0630895965641611, 'reg_alpha': 0.7884334496839835, 'reg_lambda': 0.2734792725788099}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:12,329] Trial 45 finished with value: 1.0 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.21766877641169574, 'subsample': 0.8767679257799672, 'colsample_bytree': 0.6756203282568491, 'min_child_weight': 5, 'gamma': 0.08308472286619732, 'reg_alpha': 0.42948816905796816, 'reg_lambda': 0.5139692454025158}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:12,530] Trial 46 finished with value: 1.0 and parameters: {'n_estimators': 154, 'max_depth': 11, 'learning_rate': 0.2821614521037998, 'subsample': 0.9001275835219628, 'colsample_bytree': 0.8893506055014103, 'min_child_weight': 3, 'gamma': 0.28372398773004887, 'reg_alpha': 0.5495312657739219, 'reg_lambda': 0.8561941137967801}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:12,783] Trial 47 finished with value: 1.0 and parameters: {'n_estimators': 204, 'max_depth': 9, 'learning_rate': 0.29942456212771007, 'subsample': 0.9661743588899239, 'colsample_bytree': 0.778358810756072, 'min_child_weight': 8, 'gamma': 0.046774298822757736, 'reg_alpha': 0.9962860324422824, 'reg_lambda': 0.45567676185268385}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:13,153] Trial 48 finished with value: 1.0 and parameters: {'n_estimators': 326, 'max_depth': 6, 'learning_rate': 0.23614751252014987, 'subsample': 0.6752502540594851, 'colsample_bytree': 0.6139781114763024, 'min_child_weight': 2, 'gamma': 0.10034156700606552, 'reg_alpha': 0.6424218605264617, 'reg_lambda': 0.11306282925329253}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-30 13:39:13,457] Trial 49 finished with value: 1.0 and parameters: {'n_estimators': 254, 'max_depth': 4, 'learning_rate': 0.25667636390631837, 'subsample': 0.7240973217947033, 'colsample_bytree': 0.7319174857634566, 'min_child_weight': 3, 'gamma': 0.3060760087256708, 'reg_alpha': 0.8712711222022276, 'reg_lambda': 0.020323646094238396}. Best is trial 0 with value: 1.0.\n",
            "\n",
            "üèÜ Best XGBoost parameters:\n",
            "{'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.22227824312530747, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'gamma': 0.02904180608409973, 'reg_alpha': 0.8661761457749352, 'reg_lambda': 0.6011150117432088}\n",
            "\n",
            "‚úÖ XGBoost Results:\n",
            "   ROC-AUC: 1.0000\n",
            "   Avg Precision: 1.0000\n",
            "   F1-Score: 1.0000\n",
            "   Accuracy: 1.0000\n",
            "\n",
            "üìä FRAUD CLASSIFICATION SUMMARY:\n",
            "============================================================\n",
            "                     ROC-AUC  Avg Precision  F1-Score  Accuracy\n",
            "Logistic Regression      1.0            1.0  0.994413    0.9975\n",
            "Random Forest            1.0            1.0  1.000000    1.0000\n",
            "XGBoost                  1.0            1.0  1.000000    1.0000\n",
            "============================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üî• PHASE 6: MULTI-TASK LEARNING - THE BREAKTHROUGH\n",
            "================================================================================\n",
            "\n",
            "üì¶ Preparing Data for Multi-Task Learning...\n",
            "‚öñÔ∏è Balancing fraud samples for MTL...\n",
            "‚úÖ MTL Data Ready:\n",
            "   Train: (2484, 69)\n",
            "   Test: (400, 69)\n",
            "   Fraud balance: [1242 1242]\n",
            "\n",
            "üéØ Training Multi-Task Learning Model...\n",
            "\n",
            "üöÄ Starting MTL Training on cuda...\n",
            "\n",
            "Epoch [10/100] - LR: 0.001000\n",
            "  Train Loss: 0.6716 (Demand: 0.5087, Fraud: 0.1629)\n",
            "  Test Loss:  0.3700 (Demand: 0.2333, Fraud: 0.1367)\n",
            "Epoch [20/100] - LR: 0.001000\n",
            "  Train Loss: 0.4710 (Demand: 0.4522, Fraud: 0.0188)\n",
            "  Test Loss:  0.2365 (Demand: 0.2242, Fraud: 0.0123)\n",
            "Epoch [30/100] - LR: 0.001000\n",
            "  Train Loss: 0.4346 (Demand: 0.4208, Fraud: 0.0138)\n",
            "  Test Loss:  0.2163 (Demand: 0.2112, Fraud: 0.0050)\n",
            "Epoch [40/100] - LR: 0.000500\n",
            "  Train Loss: 0.4196 (Demand: 0.4107, Fraud: 0.0089)\n",
            "  Test Loss:  0.2148 (Demand: 0.2073, Fraud: 0.0074)\n",
            "Epoch [50/100] - LR: 0.000500\n",
            "  Train Loss: 0.4055 (Demand: 0.3993, Fraud: 0.0062)\n",
            "  Test Loss:  0.1962 (Demand: 0.1954, Fraud: 0.0008)\n",
            "Epoch [60/100] - LR: 0.000500\n",
            "  Train Loss: 0.4034 (Demand: 0.3995, Fraud: 0.0039)\n",
            "  Test Loss:  0.1985 (Demand: 0.1971, Fraud: 0.0014)\n",
            "Epoch [70/100] - LR: 0.000500\n",
            "  Train Loss: 0.3976 (Demand: 0.3929, Fraud: 0.0046)\n",
            "  Test Loss:  0.1909 (Demand: 0.1902, Fraud: 0.0006)\n",
            "Epoch [80/100] - LR: 0.000250\n",
            "  Train Loss: 0.3841 (Demand: 0.3784, Fraud: 0.0057)\n",
            "  Test Loss:  0.1941 (Demand: 0.1938, Fraud: 0.0003)\n",
            "\n",
            "‚ö†Ô∏è Early stopping triggered at epoch 87\n",
            "\n",
            "‚úÖ Training completed!\n",
            "   Best test loss: 0.1829\n",
            "\n",
            "üìä Evaluating Multi-Task Learning Model...\n",
            "\n",
            "üéØ MULTI-TASK LEARNING RESULTS:\n",
            "============================================================\n",
            "\n",
            "üìà TASK 1 - Demand Forecasting:\n",
            "   RMSE: 8.1158\n",
            "   MAE: 5.7582\n",
            "   R¬≤: 0.7420\n",
            "   MAPE: 64.3804%\n",
            "\n",
            "üîí TASK 2 - Fraud Detection:\n",
            "   ROC-AUC: 1.0000\n",
            "   Avg Precision: 1.0000\n",
            "   F1-Score: 1.0000\n",
            "   Accuracy: 1.0000\n",
            "============================================================\n",
            "\n",
            "üìä COMPARATIVE ANALYSIS: MTL vs Single-Task Models\n",
            "================================================================================\n",
            "\n",
            "üéØ DEMAND FORECASTING COMPARISON:\n",
            "                   RMSE       MAE        R2       MAPE\n",
            "XGBoost        3.916222  2.291927  0.952021  29.875542\n",
            "LightGBM       4.503962  2.668902  0.936539  31.914721\n",
            "Random Forest  4.684671  2.816544  0.931345  36.007257\n",
            "MTL Model      8.115767  5.758211  0.741966  64.380426\n",
            "\n",
            "üí° MTL Improvement over best single-task (XGBoost): -107.23%\n",
            "\n",
            "üîí FRAUD DETECTION COMPARISON:\n",
            "                     ROC-AUC  Avg Precision  F1-Score  Accuracy\n",
            "Logistic Regression      1.0            1.0  0.994413    0.9975\n",
            "Random Forest            1.0            1.0  1.000000    1.0000\n",
            "XGBoost                  1.0            1.0  1.000000    1.0000\n",
            "MTL Model                1.0            1.0  1.000000    1.0000\n",
            "\n",
            "üí° MTL Improvement over best single-task (XGBoost): 0.00%\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üîç PHASE 7: FRAUD ARCHETYPE DISCOVERY (UNSUPERVISED CLUSTERING)\n",
            "================================================================================\n",
            "\n",
            "üì¶ Preparing Fraud-Related Features for Clustering...\n",
            "‚úÖ Selected 599 high-risk orders for clustering\n",
            "üîç Finding Optimal Number of Clusters...\n",
            "\n",
            "‚úÖ Optimal number of clusters: 2\n",
            "   Silhouette Score: 0.5922\n",
            "\n",
            "üéØ Performing K-Means Clustering with k=2...\n",
            "‚úÖ Clustering completed!\n",
            "\n",
            "Cluster distribution:\n",
            "Cluster\n",
            "0    576\n",
            "1     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìä FRAUD ARCHETYPE ANALYSIS:\n",
            "================================================================================\n",
            "\n",
            "üî∏ ARCHETYPE 1 (n=576)\n",
            "------------------------------------------------------------\n",
            "  Average Discount Rate: 18.05%\n",
            "  Average Order Value: $252.32\n",
            "  Average Quantity: 2.98\n",
            "  Cross-Border Rate: 100.00%\n",
            "  High Discount Rate: 99.31%\n",
            "  Cash Payment Rate: 0.00%\n",
            "  Rush Shipping Rate: 2.08%\n",
            "  Average Risk Score: 4.92\n",
            "\n",
            "  Top Payment Types:\n",
            "Type\n",
            "TRANSFER    305\n",
            "DEBIT       209\n",
            "PAYMENT      62\n",
            "\n",
            "  Top Regions:\n",
            "Order Region\n",
            "Western Europe     126\n",
            "Northern Europe     54\n",
            "Southeast Asia      50\n",
            "\n",
            "  Top Categories:\n",
            "Category Name\n",
            "Cleats             118\n",
            "Sporting Goods      94\n",
            "Women's Apparel     93\n",
            "\n",
            "üî∏ ARCHETYPE 2 (n=23)\n",
            "------------------------------------------------------------\n",
            "  Average Discount Rate: 16.83%\n",
            "  Average Order Value: $266.85\n",
            "  Average Quantity: 1.00\n",
            "  Cross-Border Rate: 100.00%\n",
            "  High Discount Rate: 95.65%\n",
            "  Cash Payment Rate: 100.00%\n",
            "  Rush Shipping Rate: 8.70%\n",
            "  Average Risk Score: 5.92\n",
            "\n",
            "  Top Payment Types:\n",
            "Type\n",
            "CASH    23\n",
            "\n",
            "  Top Regions:\n",
            "Order Region\n",
            "Western Europe    6\n",
            "Eastern Asia      5\n",
            "Southeast Asia    5\n",
            "\n",
            "  Top Categories:\n",
            "Category Name\n",
            "Sporting Goods    14\n",
            "Men's Footwear     4\n",
            "Cleats             2\n",
            "\n",
            "================================================================================\n",
            "\n",
            "üé® Performing Dimensionality Reduction...\n",
            "‚úÖ PCA completed\n",
            "   Explained variance: 42.75%\n",
            "‚úÖ t-SNE completed\n",
            "\n",
            "================================================================================\n",
            "üî¨ PHASE 8: MODEL EXPLAINABILITY WITH SHAP\n",
            "================================================================================\n",
            "\n",
            "üìä Computing SHAP Values for Demand Forecasting Model...\n",
            "‚úÖ SHAP values computed for demand forecasting\n",
            "\n",
            "üîù Top 15 Features for Demand Forecasting:\n",
            "               Feature  SHAP_Importance\n",
            "   Product_Total_Sales         7.484364\n",
            "Product_Total_Quantity         3.753974\n",
            " Region_Total_Quantity         2.771787\n",
            "                 Month         1.247873\n",
            "  Category_Total_Sales         1.187152\n",
            "   Region_Avg_Quantity         0.906209\n",
            "    Region_Total_Sales         0.876852\n",
            "          Week of Year         0.534588\n",
            "   Order Item Quantity         0.502041\n",
            "                  Year         0.416177\n",
            "              Week_Cos         0.240136\n",
            "             Month_Cos         0.216156\n",
            "                 Sales         0.175327\n",
            "   Discount_X_Quantity         0.152789\n",
            " Order Country_Encoded         0.131626\n",
            "\n",
            "üîí Computing SHAP Values for Fraud Detection Model...\n",
            "‚úÖ SHAP values computed for fraud detection\n",
            "\n",
            "üîù Top 15 Features for Fraud Detection:\n",
            "                      Feature  SHAP_Importance\n",
            "       Fraud_Risk_Proxy_Score         4.551241\n",
            "     Order Item Discount Rate         1.091356\n",
            "           High_Discount_Flag         0.529216\n",
            "        Region_X_Payment_Risk         0.250661\n",
            "           Payment_Risk_Score         0.203297\n",
            "          Discount_X_Quantity         0.099823\n",
            "Days for shipment (scheduled)         0.094634\n",
            "          Customer_Fraud_Rate         0.058827\n",
            "                 Type_Encoded         0.027230\n",
            "          Shipping_Risk_Score         0.025753\n",
            "                 Is_Month_End         0.021400\n",
            "             Price_X_Discount         0.012586\n",
            "      Category_Total_Quantity         0.010127\n",
            "           Customer_Avg_Sales         0.005649\n",
            "          Product_Total_Sales         0.005562\n",
            "\n",
            "================================================================================\n",
            "üí° KEY INSIGHTS FROM EXPLAINABILITY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "üîó Shared Important Features (appear in top 20 for both tasks):\n",
            "  ‚Ä¢ Price_X_Discount\n",
            "    - Demand rank: #55, Fraud rank: #55\n",
            "  ‚Ä¢ Week of Year\n",
            "    - Demand rank: #8, Fraud rank: #8\n",
            "  ‚Ä¢ Sales\n",
            "    - Demand rank: #4, Fraud rank: #4\n",
            "  ‚Ä¢ Product_Total_Sales\n",
            "    - Demand rank: #42, Fraud rank: #42\n",
            "  ‚Ä¢ Order Item Quantity\n",
            "    - Demand rank: #3, Fraud rank: #3\n",
            "  ‚Ä¢ Category_Total_Quantity\n",
            "    - Demand rank: #50, Fraud rank: #50\n",
            "  ‚Ä¢ Discount_X_Quantity\n",
            "    - Demand rank: #54, Fraud rank: #54\n",
            "  ‚Ä¢ Customer_Avg_Sales\n",
            "    - Demand rank: #34, Fraud rank: #34\n",
            "\n",
            "üìà Business Implications:\n",
            "  ‚Ä¢ Discount rate is critical for BOTH demand forecasting and fraud detection\n",
            "  ‚Ä¢ Regional patterns influence both legitimate demand and fraud risk\n",
            "  ‚Ä¢ Payment types serve as strong fraud indicators but less impact on demand\n",
            "  ‚Ä¢ Customer behavior aggregations help identify both trends and anomalies\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üíæ PHASE 9: SAVING RESULTS & MODELS\n",
            "================================================================================\n",
            "\n",
            "üìä Saving Performance Metrics...\n",
            "‚úÖ Performance metrics saved\n",
            "ü§ñ Saving Trained Models...\n",
            "‚úÖ Models saved\n",
            "üîç Saving Clustering Results...\n",
            "‚úÖ Clustering results saved\n",
            "üî¨ Saving SHAP Results...\n",
            "‚úÖ SHAP results saved\n",
            "üìù Creating Summary Report...\n",
            "‚úÖ Summary report created\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ALL RESULTS SAVED TO 'results/' DIRECTORY\n",
            "================================================================================\n",
            "\n",
            "\n",
            "üèÜ PROJECT COMPLETE!\n",
            "\n",
            "üìÅ OUTPUT FILES:\n",
            "  ‚Ä¢ results/demand_forecasting_results.csv\n",
            "  ‚Ä¢ results/fraud_detection_results.csv\n",
            "  ‚Ä¢ results/fraud_archetype_profiles.csv\n",
            "  ‚Ä¢ results/feature_importance_demand.csv\n",
            "  ‚Ä¢ results/feature_importance_fraud.csv\n",
            "  ‚Ä¢ results/summary_report.json\n",
            "  ‚Ä¢ results/*.pkl (models and data)\n",
            "  ‚Ä¢ best_mtl_model.pth (PyTorch MTL model)\n",
            "\n",
            "‚ú® Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi ƒë·ªì √°n! ‚ú®\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# EXPLAINABLE MULTI-TASK LEARNING FOR SUPPLY CHAIN - FIXED VERSION\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q xgboost lightgbm catboost shap imbalanced-learn optuna torch torchvision\n",
        "\n",
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import gc\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    roc_auc_score, precision_recall_curve, average_precision_score,\n",
        "    confusion_matrix, classification_report, f1_score, accuracy_score\n",
        ")\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Tree-based models\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# Explainability\n",
        "import shap\n",
        "\n",
        "# Imbalanced learning\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# Optimization\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üî• Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Determine XGBoost tree method\n",
        "TREE_METHOD = 'hist'  # XGBoost 'gpu_hist' deprecated, use 'hist' with device='cuda'\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 1: DATA LOADING & INITIAL EXPLORATION\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä PHASE 1: DATA LOADING & EXPLORATION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('DataCo_cleaned.csv')\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìà Shape: {df.shape}\")\n",
        "print(f\"üìù Columns: {df.columns.tolist()}\\n\")\n",
        "\n",
        "# Basic info\n",
        "print(\"üîç Data Types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nüìä Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 2: ADVANCED FEATURE ENGINEERING\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîß PHASE 2: ADVANCED FEATURE ENGINEERING\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create a copy for feature engineering\n",
        "df_feat = df.copy()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.1 TEMPORAL FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"‚è∞ Creating Temporal Features...\")\n",
        "\n",
        "df_feat['Quarter'] = (df_feat['Month'] - 1) // 3 + 1\n",
        "df_feat['Is_Weekend'] = df_feat['Day of Week'].isin([6, 7]).astype(int)\n",
        "df_feat['Is_Month_Start'] = (df_feat['Week of Year'] % 4 == 1).astype(int)\n",
        "df_feat['Is_Month_End'] = (df_feat['Week of Year'] % 4 == 0).astype(int)\n",
        "df_feat['Season'] = df_feat['Month'].map({\n",
        "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
        "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
        "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
        "})\n",
        "\n",
        "# Cyclical encoding\n",
        "df_feat['Month_Sin'] = np.sin(2 * np.pi * df_feat['Month'] / 12)\n",
        "df_feat['Month_Cos'] = np.cos(2 * np.pi * df_feat['Month'] / 12)\n",
        "df_feat['Week_Sin'] = np.sin(2 * np.pi * df_feat['Week of Year'] / 52)\n",
        "df_feat['Week_Cos'] = np.cos(2 * np.pi * df_feat['Week of Year'] / 52)\n",
        "df_feat['Day_Sin'] = np.sin(2 * np.pi * df_feat['Day of Week'] / 7)\n",
        "df_feat['Day_Cos'] = np.cos(2 * np.pi * df_feat['Day of Week'] / 7)\n",
        "\n",
        "print(f\"‚úÖ Created 12 temporal features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.2 BEHAVIORAL FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üë• Creating Behavioral Features...\")\n",
        "\n",
        "# Discount intensity\n",
        "df_feat['Discount_Level'] = pd.cut(\n",
        "    df_feat['Order Item Discount Rate'],\n",
        "    bins=[-0.01, 0.0, 0.05, 0.15, 0.3, 1.0],\n",
        "    labels=['No_Discount', 'Low', 'Medium', 'High', 'Very_High']\n",
        ")\n",
        "\n",
        "df_feat['High_Discount_Flag'] = (df_feat['Order Item Discount Rate'] > 0.15).astype(int)\n",
        "df_feat['Extreme_Discount_Flag'] = (df_feat['Order Item Discount Rate'] > 0.3).astype(int)\n",
        "\n",
        "# Price per unit\n",
        "df_feat['Price_Per_Unit'] = df_feat['Sales'] / df_feat['Order Item Quantity'].replace(0, 1)\n",
        "\n",
        "# Value bands\n",
        "df_feat['Order_Value_Band'] = pd.cut(\n",
        "    df_feat['Sales'],\n",
        "    bins=[-np.inf, 50, 200, 500, 1000, np.inf],\n",
        "    labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High']\n",
        ")\n",
        "\n",
        "# Quantity bands\n",
        "df_feat['Quantity_Band'] = pd.cut(\n",
        "    df_feat['Order Item Quantity'],\n",
        "    bins=[0, 1, 3, 5, 10, np.inf],\n",
        "    labels=['Single', 'Small', 'Medium', 'Large', 'Bulk']\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Created behavioral features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.3 GEOGRAPHICAL & LOGISTICS FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üåç Creating Geographical Features...\")\n",
        "\n",
        "# Cross-border flag\n",
        "df_feat['Is_Cross_Border'] = (\n",
        "    df_feat['Customer Country'] != df_feat['Order Country']\n",
        ").astype(int)\n",
        "\n",
        "# International shipping\n",
        "df_feat['Is_International'] = df_feat['Customer Country'].apply(\n",
        "    lambda x: 0 if x in ['EE. UU.', 'United States'] else 1\n",
        ")\n",
        "\n",
        "# Geographic distance proxy\n",
        "df_feat['Customer_Order_Same_Region'] = (\n",
        "    df_feat['Customer Country'] == df_feat['Order Country']\n",
        ").astype(int)\n",
        "\n",
        "# Shipping mode risk\n",
        "shipping_risk_map = {\n",
        "    'Standard Class': 1,\n",
        "    'Second Class': 2,\n",
        "    'First Class': 3,\n",
        "    'Same Day': 4\n",
        "}\n",
        "df_feat['Shipping_Risk_Score'] = df_feat['Shipping Mode'].map(shipping_risk_map).fillna(1)\n",
        "\n",
        "print(f\"‚úÖ Created geographical features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.4 PAYMENT & RISK PROXY FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üí≥ Creating Payment & Risk Features...\")\n",
        "\n",
        "# Payment type risk scoring\n",
        "payment_risk_map = {\n",
        "    'PAYMENT': 1,\n",
        "    'DEBIT': 2,\n",
        "    'TRANSFER': 3,\n",
        "    'CASH': 4\n",
        "}\n",
        "df_feat['Payment_Risk_Score'] = df_feat['Type'].map(payment_risk_map)\n",
        "\n",
        "# High-risk payment combinations\n",
        "df_feat['Cash_High_Discount'] = (\n",
        "    (df_feat['Type'] == 'CASH') & (df_feat['High_Discount_Flag'] == 1)\n",
        ").astype(int)\n",
        "\n",
        "df_feat['Cash_Cross_Border'] = (\n",
        "    (df_feat['Type'] == 'CASH') & (df_feat['Is_Cross_Border'] == 1)\n",
        ").astype(int)\n",
        "\n",
        "df_feat['Rush_Shipping_High_Discount'] = (\n",
        "    (df_feat['Shipping Mode'] == 'Same Day') & (df_feat['High_Discount_Flag'] == 1)\n",
        ").astype(int)\n",
        "\n",
        "# Composite fraud risk proxy\n",
        "df_feat['Fraud_Risk_Proxy_Score'] = (\n",
        "    df_feat['Payment_Risk_Score'] * 0.3 +\n",
        "    df_feat['High_Discount_Flag'] * 2.0 +\n",
        "    df_feat['Is_Cross_Border'] * 1.5 +\n",
        "    df_feat['Shipping_Risk_Score'] * 0.5 +\n",
        "    df_feat['Extreme_Discount_Flag'] * 3.0\n",
        ")\n",
        "\n",
        "# Binary fraud proxy\n",
        "fraud_threshold = df_feat['Fraud_Risk_Proxy_Score'].quantile(0.75)\n",
        "df_feat['Fraud_Risk_Label'] = (\n",
        "    df_feat['Fraud_Risk_Proxy_Score'] > fraud_threshold\n",
        ").astype(int)\n",
        "\n",
        "print(f\"‚úÖ Fraud Risk Distribution:\")\n",
        "print(df_feat['Fraud_Risk_Label'].value_counts())\n",
        "print(f\"   Fraud Rate: {df_feat['Fraud_Risk_Label'].mean()*100:.2f}%\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.5 AGGREGATION FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä Creating Aggregation Features...\")\n",
        "\n",
        "# Customer-level aggregations\n",
        "customer_agg = df_feat.groupby('Customer City').agg({\n",
        "    'Order Item Quantity': ['mean', 'std', 'sum'],\n",
        "    'Sales': ['mean', 'std', 'sum'],\n",
        "    'Order Item Discount Rate': 'mean',\n",
        "    'Fraud_Risk_Label': 'mean'\n",
        "}).reset_index()\n",
        "customer_agg.columns = ['Customer City',\n",
        "                        'Customer_Avg_Quantity', 'Customer_Std_Quantity', 'Customer_Total_Quantity',\n",
        "                        'Customer_Avg_Sales', 'Customer_Std_Sales', 'Customer_Total_Sales',\n",
        "                        'Customer_Avg_Discount', 'Customer_Fraud_Rate']\n",
        "\n",
        "df_feat = df_feat.merge(customer_agg, on='Customer City', how='left')\n",
        "\n",
        "# Product-level aggregations\n",
        "product_agg = df_feat.groupby('Product Name').agg({\n",
        "    'Order Item Quantity': ['mean', 'sum'],\n",
        "    'Sales': ['mean', 'sum'],\n",
        "    'Fraud_Risk_Label': 'mean'\n",
        "}).reset_index()\n",
        "product_agg.columns = ['Product Name',\n",
        "                       'Product_Avg_Quantity', 'Product_Total_Quantity',\n",
        "                       'Product_Avg_Sales', 'Product_Total_Sales',\n",
        "                       'Product_Fraud_Rate']\n",
        "\n",
        "df_feat = df_feat.merge(product_agg, on='Product Name', how='left')\n",
        "\n",
        "# Region-level aggregations\n",
        "region_agg = df_feat.groupby('Order Region').agg({\n",
        "    'Order Item Quantity': ['mean', 'sum'],\n",
        "    'Sales': ['mean', 'sum'],\n",
        "    'Fraud_Risk_Label': 'mean'\n",
        "}).reset_index()\n",
        "region_agg.columns = ['Order Region',\n",
        "                      'Region_Avg_Quantity', 'Region_Total_Quantity',\n",
        "                      'Region_Avg_Sales', 'Region_Total_Sales',\n",
        "                      'Region_Fraud_Rate']\n",
        "\n",
        "df_feat = df_feat.merge(region_agg, on='Order Region', how='left')\n",
        "\n",
        "# Category-level aggregations\n",
        "category_agg = df_feat.groupby('Category Name').agg({\n",
        "    'Order Item Quantity': ['mean', 'sum'],\n",
        "    'Sales': ['mean', 'sum'],\n",
        "    'Fraud_Risk_Label': 'mean'\n",
        "}).reset_index()\n",
        "category_agg.columns = ['Category Name',\n",
        "                        'Category_Avg_Quantity', 'Category_Total_Quantity',\n",
        "                        'Category_Avg_Sales', 'Category_Total_Sales',\n",
        "                        'Category_Fraud_Rate']\n",
        "\n",
        "df_feat = df_feat.merge(category_agg, on='Category Name', how='left')\n",
        "\n",
        "print(f\"‚úÖ Created aggregation features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.6 INTERACTION FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üîó Creating Interaction Features...\")\n",
        "\n",
        "df_feat['Discount_X_Quantity'] = df_feat['Order Item Discount Rate'] * df_feat['Order Item Quantity']\n",
        "df_feat['Price_X_Discount'] = df_feat['Price_Per_Unit'] * df_feat['Order Item Discount Rate']\n",
        "df_feat['Region_X_Payment_Risk'] = df_feat['Region_Fraud_Rate'] * df_feat['Payment_Risk_Score']\n",
        "\n",
        "print(f\"‚úÖ Created interaction features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2.7 MONTHLY DEMAND AGGREGATION\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìÖ Creating Monthly Demand Target...\")\n",
        "\n",
        "# Create Product √ó Region √ó Time key\n",
        "df_feat['Product_Region_Key'] = (\n",
        "    df_feat['Product Name'].astype(str) + '_' +\n",
        "    df_feat['Order Region'].astype(str)\n",
        ")\n",
        "\n",
        "df_feat['Year_Month'] = df_feat['Year'].astype(str) + '_' + df_feat['Month'].astype(str).str.zfill(2)\n",
        "\n",
        "# Monthly demand aggregation\n",
        "monthly_demand = df_feat.groupby(['Product_Region_Key', 'Year_Month']).agg({\n",
        "    'Order Item Quantity': 'sum',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "monthly_demand.columns = ['Product_Region_Key', 'Year_Month', 'Monthly_Demand', 'Monthly_Sales']\n",
        "\n",
        "# Merge back\n",
        "df_feat = df_feat.merge(monthly_demand, on=['Product_Region_Key', 'Year_Month'], how='left')\n",
        "\n",
        "print(f\"‚úÖ Monthly demand aggregated\")\n",
        "print(f\"   Unique Product-Region combinations: {df_feat['Product_Region_Key'].nunique()}\")\n",
        "print(f\"   Demand range: {df_feat['Monthly_Demand'].min():.0f} - {df_feat['Monthly_Demand'].max():.0f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ FEATURE ENGINEERING COMPLETE!\")\n",
        "print(f\"üìä Final dataset shape: {df_feat.shape}\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 3: DATA PREPROCESSING & ENCODING\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî® PHASE 3: DATA PREPROCESSING & ENCODING\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create a copy for modeling\n",
        "df_model = df_feat.copy()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3.1 HANDLE CATEGORICAL VARIABLES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üè∑Ô∏è Encoding Categorical Variables...\")\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_cols = [\n",
        "    'Type', 'Category Name', 'Customer Country', 'Customer Segment',\n",
        "    'Department Name', 'Market', 'Order Country', 'Order Region',\n",
        "    'Shipping Mode', 'Season', 'Discount_Level', 'Order_Value_Band',\n",
        "    'Quantity_Band'\n",
        "]\n",
        "\n",
        "# Label encoding\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    if col in df_model.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_model[f'{col}_Encoded'] = le.fit_transform(df_model[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "print(f\"‚úÖ Encoded {len(categorical_cols)} categorical features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3.2 SELECT FEATURES FOR MODELING\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üéØ Selecting Features for Modeling...\")\n",
        "\n",
        "# Numerical features\n",
        "numerical_features = [\n",
        "    'Days for shipment (scheduled)', 'Order Item Discount Rate', 'Order Item Quantity',\n",
        "    'Sales', 'Day of Week', 'Month', 'Year', 'Week of Year', 'Quarter',\n",
        "    'Is_Weekend', 'Is_Month_Start', 'Is_Month_End',\n",
        "    'Month_Sin', 'Month_Cos', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos',\n",
        "    'High_Discount_Flag', 'Extreme_Discount_Flag', 'Price_Per_Unit',\n",
        "    'Is_Cross_Border', 'Is_International', 'Customer_Order_Same_Region',\n",
        "    'Shipping_Risk_Score', 'Payment_Risk_Score',\n",
        "    'Cash_High_Discount', 'Cash_Cross_Border', 'Rush_Shipping_High_Discount',\n",
        "    'Fraud_Risk_Proxy_Score',\n",
        "    'Customer_Avg_Quantity', 'Customer_Std_Quantity', 'Customer_Total_Quantity',\n",
        "    'Customer_Avg_Sales', 'Customer_Std_Sales', 'Customer_Total_Sales',\n",
        "    'Customer_Avg_Discount', 'Customer_Fraud_Rate',\n",
        "    'Product_Avg_Quantity', 'Product_Total_Quantity', 'Product_Avg_Sales',\n",
        "    'Product_Total_Sales', 'Product_Fraud_Rate',\n",
        "    'Region_Avg_Quantity', 'Region_Total_Quantity', 'Region_Avg_Sales',\n",
        "    'Region_Total_Sales', 'Region_Fraud_Rate',\n",
        "    'Category_Avg_Quantity', 'Category_Total_Quantity', 'Category_Avg_Sales',\n",
        "    'Category_Total_Sales', 'Category_Fraud_Rate',\n",
        "    'Discount_X_Quantity', 'Price_X_Discount', 'Region_X_Payment_Risk'\n",
        "]\n",
        "\n",
        "# Encoded categorical features\n",
        "encoded_features = [f'{col}_Encoded' for col in categorical_cols if f'{col}_Encoded' in df_model.columns]\n",
        "\n",
        "# All features\n",
        "all_features = numerical_features + encoded_features\n",
        "\n",
        "# Handle missing values\n",
        "for col in all_features:\n",
        "    if col in df_model.columns:\n",
        "        df_model[col] = df_model[col].fillna(df_model[col].median())\n",
        "\n",
        "print(f\"‚úÖ Total features: {len(all_features)}\")\n",
        "print(f\"   - Numerical: {len(numerical_features)}\")\n",
        "print(f\"   - Encoded Categorical: {len(encoded_features)}\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3.3 OUTLIER HANDLING\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üîç Handling Outliers...\")\n",
        "\n",
        "def cap_outliers(df, column, lower_quantile=0.01, upper_quantile=0.99):\n",
        "    lower = df[column].quantile(lower_quantile)\n",
        "    upper = df[column].quantile(upper_quantile)\n",
        "    df[column] = df[column].clip(lower, upper)\n",
        "    return df\n",
        "\n",
        "outlier_cols = ['Sales', 'Order Item Quantity', 'Price_Per_Unit', 'Monthly_Demand']\n",
        "for col in outlier_cols:\n",
        "    if col in df_model.columns:\n",
        "        df_model = cap_outliers(df_model, col)\n",
        "\n",
        "print(f\"‚úÖ Outliers capped for {len(outlier_cols)} features\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3.4 PREPARE DATASETS FOR TASKS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üì¶ Preparing Datasets for Each Task...\")\n",
        "\n",
        "# Remove any remaining NaN\n",
        "df_model = df_model.dropna(subset=all_features + ['Monthly_Demand', 'Fraud_Risk_Label'])\n",
        "\n",
        "# Features matrix\n",
        "X = df_model[all_features].values\n",
        "\n",
        "# Task 1: Monthly Demand Forecasting\n",
        "y_demand = df_model['Monthly_Demand'].values\n",
        "\n",
        "# Task 2: Fraud Risk Classification\n",
        "y_fraud = df_model['Fraud_Risk_Label'].values\n",
        "\n",
        "print(f\"‚úÖ Dataset prepared:\")\n",
        "print(f\"   - X shape: {X.shape}\")\n",
        "print(f\"   - y_demand shape: {y_demand.shape}\")\n",
        "print(f\"   - y_fraud shape: {y_fraud.shape}\")\n",
        "print(f\"   - Fraud class distribution: {np.bincount(y_fraud)}\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 4: TASK 1 - DEMAND FORECASTING\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìà PHASE 4: TASK 1 - DEMAND FORECASTING\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Train-test split\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
        "    X, y_demand, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train_d.shape}, Test set: {X_test_d.shape}\\n\")\n",
        "\n",
        "# Scale features\n",
        "scaler_demand = RobustScaler()\n",
        "X_train_d_scaled = scaler_demand.fit_transform(X_train_d)\n",
        "X_test_d_scaled = scaler_demand.transform(X_test_d)\n",
        "\n",
        "# Dictionary to store results\n",
        "demand_results = {}\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4.1 BASELINE: Random Forest\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üå≤ Training Baseline: Random Forest Regressor...\")\n",
        "\n",
        "rf_demand = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_demand.fit(X_train_d, y_train_d)\n",
        "y_pred_rf = rf_demand.predict(X_test_d)\n",
        "\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_d, y_pred_rf))\n",
        "mae_rf = mean_absolute_error(y_test_d, y_pred_rf)\n",
        "r2_rf = r2_score(y_test_d, y_pred_rf)\n",
        "mape_rf = np.mean(np.abs((y_test_d - y_pred_rf) / (y_test_d + 1))) * 100\n",
        "\n",
        "demand_results['Random Forest'] = {\n",
        "    'RMSE': rmse_rf,\n",
        "    'MAE': mae_rf,\n",
        "    'R2': r2_rf,\n",
        "    'MAPE': mape_rf\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Random Forest Results:\")\n",
        "print(f\"   RMSE: {rmse_rf:.4f}\")\n",
        "print(f\"   MAE: {mae_rf:.4f}\")\n",
        "print(f\"   R¬≤: {r2_rf:.4f}\")\n",
        "print(f\"   MAPE: {mape_rf:.4f}%\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4.2 MAIN MODEL: XGBoost with Hyperparameter Tuning\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üöÄ Training Main Model: XGBoost with Optuna Tuning...\")\n",
        "\n",
        "def objective_xgb_demand(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),\n",
        "        'tree_method': TREE_METHOD,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    if USE_GPU:\n",
        "        params['device'] = 'cuda'\n",
        "\n",
        "    model = XGBRegressor(**params)\n",
        "    model.fit(X_train_d, y_train_d, eval_set=[(X_test_d, y_test_d)], verbose=False)\n",
        "    preds = model.predict(X_test_d)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_d, preds))\n",
        "    return rmse\n",
        "\n",
        "# Run Optuna optimization\n",
        "study_xgb_demand = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=TPESampler(seed=42)\n",
        ")\n",
        "study_xgb_demand.optimize(objective_xgb_demand, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nüèÜ Best XGBoost parameters:\")\n",
        "print(study_xgb_demand.best_params)\n",
        "\n",
        "# Train final XGBoost model\n",
        "best_params_xgb_demand = study_xgb_demand.best_params\n",
        "best_params_xgb_demand['tree_method'] = TREE_METHOD\n",
        "best_params_xgb_demand['random_state'] = 42\n",
        "if USE_GPU:\n",
        "    best_params_xgb_demand['device'] = 'cuda'\n",
        "\n",
        "xgb_demand = XGBRegressor(**best_params_xgb_demand)\n",
        "xgb_demand.fit(X_train_d, y_train_d, eval_set=[(X_test_d, y_test_d)], verbose=False)\n",
        "y_pred_xgb = xgb_demand.predict(X_test_d)\n",
        "\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test_d, y_pred_xgb))\n",
        "mae_xgb = mean_absolute_error(y_test_d, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test_d, y_pred_xgb)\n",
        "mape_xgb = np.mean(np.abs((y_test_d - y_pred_xgb) / (y_test_d + 1))) * 100\n",
        "\n",
        "demand_results['XGBoost'] = {\n",
        "    'RMSE': rmse_xgb,\n",
        "    'MAE': mae_xgb,\n",
        "    'R2': r2_xgb,\n",
        "    'MAPE': mape_xgb\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ XGBoost Results:\")\n",
        "print(f\"   RMSE: {rmse_xgb:.4f}\")\n",
        "print(f\"   MAE: {mae_xgb:.4f}\")\n",
        "print(f\"   R¬≤: {r2_xgb:.4f}\")\n",
        "print(f\"   MAPE: {mape_xgb:.4f}%\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4.3 ADVANCED: LightGBM\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üí° Training Advanced Model: LightGBM...\")\n",
        "\n",
        "lgb_params = {\n",
        "    'n_estimators': 300,\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'min_child_samples': 20,\n",
        "    'random_state': 42,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "if USE_GPU:\n",
        "    lgb_params['device'] = 'gpu'\n",
        "\n",
        "lgb_demand = LGBMRegressor(**lgb_params)\n",
        "lgb_demand.fit(X_train_d, y_train_d)\n",
        "y_pred_lgb = lgb_demand.predict(X_test_d)\n",
        "\n",
        "rmse_lgb = np.sqrt(mean_squared_error(y_test_d, y_pred_lgb))\n",
        "mae_lgb = mean_absolute_error(y_test_d, y_pred_lgb)\n",
        "r2_lgb = r2_score(y_test_d, y_pred_lgb)\n",
        "mape_lgb = np.mean(np.abs((y_test_d - y_pred_lgb) / (y_test_d + 1))) * 100\n",
        "\n",
        "demand_results['LightGBM'] = {\n",
        "    'RMSE': rmse_lgb,\n",
        "    'MAE': mae_lgb,\n",
        "    'R2': r2_lgb,\n",
        "    'MAPE': mape_lgb\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ LightGBM Results:\")\n",
        "print(f\"   RMSE: {rmse_lgb:.4f}\")\n",
        "print(f\"   MAE: {mae_lgb:.4f}\")\n",
        "print(f\"   R¬≤: {r2_lgb:.4f}\")\n",
        "print(f\"   MAPE: {mape_lgb:.4f}%\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4.4 Summary\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä DEMAND FORECASTING SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "demand_df = pd.DataFrame(demand_results).T\n",
        "print(demand_df.to_string())\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 5: TASK 2 - FRAUD RISK CLASSIFICATION\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîí PHASE 5: TASK 2 - FRAUD RISK CLASSIFICATION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Train-test split\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
        "    X, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train_f.shape}, Test set: {X_test_f.shape}\")\n",
        "print(f\"Train fraud rate: {y_train_f.mean()*100:.2f}%\")\n",
        "print(f\"Test fraud rate: {y_test_f.mean()*100:.2f}%\\n\")\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "print(\"‚öñÔ∏è Handling Class Imbalance with SMOTE...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_f_balanced, y_train_f_balanced = smote.fit_resample(X_train_f, y_train_f)\n",
        "\n",
        "print(f\"After SMOTE: {X_train_f_balanced.shape}\")\n",
        "print(f\"Class distribution: {np.bincount(y_train_f_balanced)}\\n\")\n",
        "\n",
        "# Dictionary to store results\n",
        "fraud_results = {}\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5.1 BASELINE: Logistic Regression\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä Training Baseline: Logistic Regression...\")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "scaler_fraud_lr = RobustScaler()\n",
        "X_train_f_scaled = scaler_fraud_lr.fit_transform(X_train_f_balanced)\n",
        "X_test_f_scaled = scaler_fraud_lr.transform(X_test_f)\n",
        "\n",
        "lr_fraud = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "lr_fraud.fit(X_train_f_scaled, y_train_f_balanced)\n",
        "y_pred_lr = lr_fraud.predict(X_test_f_scaled)\n",
        "y_pred_lr_proba = lr_fraud.predict_proba(X_test_f_scaled)[:, 1]\n",
        "\n",
        "roc_auc_lr = roc_auc_score(y_test_f, y_pred_lr_proba)\n",
        "avg_precision_lr = average_precision_score(y_test_f, y_pred_lr_proba)\n",
        "f1_lr = f1_score(y_test_f, y_pred_lr)\n",
        "acc_lr = accuracy_score(y_test_f, y_pred_lr)\n",
        "\n",
        "fraud_results['Logistic Regression'] = {\n",
        "    'ROC-AUC': roc_auc_lr,\n",
        "    'Avg Precision': avg_precision_lr,\n",
        "    'F1-Score': f1_lr,\n",
        "    'Accuracy': acc_lr\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Logistic Regression Results:\")\n",
        "print(f\"   ROC-AUC: {roc_auc_lr:.4f}\")\n",
        "print(f\"   Avg Precision: {avg_precision_lr:.4f}\")\n",
        "print(f\"   F1-Score: {f1_lr:.4f}\")\n",
        "print(f\"   Accuracy: {acc_lr:.4f}\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5.2 MAIN MODEL: Random Forest\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üå≤ Training Main Model: Random Forest Classifier...\")\n",
        "\n",
        "rf_fraud = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_fraud.fit(X_train_f_balanced, y_train_f_balanced)\n",
        "y_pred_rf_f = rf_fraud.predict(X_test_f)\n",
        "y_pred_rf_proba = rf_fraud.predict_proba(X_test_f)[:, 1]\n",
        "\n",
        "roc_auc_rf = roc_auc_score(y_test_f, y_pred_rf_proba)\n",
        "avg_precision_rf = average_precision_score(y_test_f, y_pred_rf_proba)\n",
        "f1_rf_f = f1_score(y_test_f, y_pred_rf_f)\n",
        "acc_rf_f = accuracy_score(y_test_f, y_pred_rf_f)\n",
        "\n",
        "fraud_results['Random Forest'] = {\n",
        "    'ROC-AUC': roc_auc_rf,\n",
        "    'Avg Precision': avg_precision_rf,\n",
        "    'F1-Score': f1_rf_f,\n",
        "    'Accuracy': acc_rf_f\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Random Forest Results:\")\n",
        "print(f\"   ROC-AUC: {roc_auc_rf:.4f}\")\n",
        "print(f\"   Avg Precision: {avg_precision_rf:.4f}\")\n",
        "print(f\"   F1-Score: {f1_rf_f:.4f}\")\n",
        "print(f\"   Accuracy: {acc_rf_f:.4f}\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5.3 ADVANCED: XGBoost with Tuning\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üöÄ Training Advanced Model: XGBoost Classifier...\")\n",
        "\n",
        "def objective_xgb_fraud(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),\n",
        "        'scale_pos_weight': len(y_train_f_balanced[y_train_f_balanced == 0]) / len(y_train_f_balanced[y_train_f_balanced == 1]),\n",
        "        'tree_method': TREE_METHOD,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    if USE_GPU:\n",
        "        params['device'] = 'cuda'\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train_f_balanced, y_train_f_balanced, eval_set=[(X_test_f, y_test_f)], verbose=False)\n",
        "    preds_proba = model.predict_proba(X_test_f)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_test_f, preds_proba)\n",
        "    return roc_auc\n",
        "\n",
        "study_xgb_fraud = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=TPESampler(seed=42)\n",
        ")\n",
        "study_xgb_fraud.optimize(objective_xgb_fraud, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nüèÜ Best XGBoost parameters:\")\n",
        "print(study_xgb_fraud.best_params)\n",
        "\n",
        "# Train final model\n",
        "best_params_xgb_fraud = study_xgb_fraud.best_params\n",
        "best_params_xgb_fraud['scale_pos_weight'] = len(y_train_f_balanced[y_train_f_balanced == 0]) / len(y_train_f_balanced[y_train_f_balanced == 1])\n",
        "best_params_xgb_fraud['tree_method'] = TREE_METHOD\n",
        "best_params_xgb_fraud['random_state'] = 42\n",
        "if USE_GPU:\n",
        "    best_params_xgb_fraud['device'] = 'cuda'\n",
        "\n",
        "xgb_fraud = XGBClassifier(**best_params_xgb_fraud)\n",
        "xgb_fraud.fit(X_train_f_balanced, y_train_f_balanced, eval_set=[(X_test_f, y_test_f)], verbose=False)\n",
        "y_pred_xgb_f = xgb_fraud.predict(X_test_f)\n",
        "y_pred_xgb_proba = xgb_fraud.predict_proba(X_test_f)[:, 1]\n",
        "\n",
        "roc_auc_xgb_f = roc_auc_score(y_test_f, y_pred_xgb_proba)\n",
        "avg_precision_xgb = average_precision_score(y_test_f, y_pred_xgb_proba)\n",
        "f1_xgb_f = f1_score(y_test_f, y_pred_xgb_f)\n",
        "acc_xgb_f = accuracy_score(y_test_f, y_pred_xgb_f)\n",
        "\n",
        "fraud_results['XGBoost'] = {\n",
        "    'ROC-AUC': roc_auc_xgb_f,\n",
        "    'Avg Precision': avg_precision_xgb,\n",
        "    'F1-Score': f1_xgb_f,\n",
        "    'Accuracy': acc_xgb_f\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ XGBoost Results:\")\n",
        "print(f\"   ROC-AUC: {roc_auc_xgb_f:.4f}\")\n",
        "print(f\"   Avg Precision: {avg_precision_xgb:.4f}\")\n",
        "print(f\"   F1-Score: {f1_xgb_f:.4f}\")\n",
        "print(f\"   Accuracy: {acc_xgb_f:.4f}\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5.4 Summary\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä FRAUD CLASSIFICATION SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "fraud_df = pd.DataFrame(fraud_results).T\n",
        "print(fraud_df.to_string())\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 6: MULTI-TASK LEARNING (MTL) - CORE CONTRIBUTION\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî• PHASE 6: MULTI-TASK LEARNING - THE BREAKTHROUGH\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6.1 MTL ARCHITECTURE DEFINITION\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Task Learning Model with Shared Representations\n",
        "\n",
        "    Architecture:\n",
        "    - Shared Feature Extractor (3 layers)\n",
        "    - Task-Specific Heads:\n",
        "        * Demand Head (Regression)\n",
        "        * Fraud Head (Classification)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], dropout=0.3):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "\n",
        "        # Shared Feature Extractor\n",
        "        self.shared_layer1 = nn.Linear(input_dim, hidden_dims[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dims[0])\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.shared_layer2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dims[1])\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.shared_layer3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_dims[2])\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        # Task 1: Demand Forecasting Head (Regression)\n",
        "        self.demand_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[2], 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "        # Task 2: Fraud Detection Head (Classification)\n",
        "        self.fraud_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[2], 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shared representation learning\n",
        "        x = F.relu(self.bn1(self.shared_layer1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.shared_layer2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        shared_repr = F.relu(self.bn3(self.shared_layer3(x)))\n",
        "        shared_repr = self.dropout3(shared_repr)\n",
        "\n",
        "        # Task-specific outputs\n",
        "        demand_output = self.demand_head(shared_repr)\n",
        "        fraud_output = self.fraud_head(shared_repr)\n",
        "\n",
        "        return demand_output, fraud_output, shared_repr\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6.2 PREPARE DATA FOR MTL\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üì¶ Preparing Data for Multi-Task Learning...\")\n",
        "\n",
        "# Split data\n",
        "X_train_mtl, X_test_mtl, y_train_d_mtl, y_test_d_mtl, y_train_f_mtl, y_test_f_mtl = train_test_split(\n",
        "    X, y_demand, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_mtl = RobustScaler()\n",
        "X_train_mtl_scaled = scaler_mtl.fit_transform(X_train_mtl)\n",
        "X_test_mtl_scaled = scaler_mtl.transform(X_test_mtl)\n",
        "\n",
        "# Normalize demand target\n",
        "demand_scaler = RobustScaler()\n",
        "y_train_d_mtl_scaled = demand_scaler.fit_transform(y_train_d_mtl.reshape(-1, 1)).flatten()\n",
        "y_test_d_mtl_scaled = demand_scaler.transform(y_test_d_mtl.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Handle class imbalance for fraud task\n",
        "print(\"‚öñÔ∏è Balancing fraud samples for MTL...\")\n",
        "smote_mtl = SMOTE(random_state=42)\n",
        "X_train_mtl_balanced, y_train_f_mtl_balanced = smote_mtl.fit_resample(X_train_mtl_scaled, y_train_f_mtl)\n",
        "\n",
        "# Get corresponding demand labels for balanced samples\n",
        "indices_balanced = smote_mtl.fit_resample(\n",
        "    np.arange(len(X_train_mtl_scaled)).reshape(-1, 1),\n",
        "    y_train_f_mtl\n",
        ")[0].flatten()\n",
        "\n",
        "y_train_d_mtl_balanced = np.array([y_train_d_mtl_scaled[i % len(y_train_d_mtl_scaled)] for i in indices_balanced])\n",
        "\n",
        "print(f\"‚úÖ MTL Data Ready:\")\n",
        "print(f\"   Train: {X_train_mtl_balanced.shape}\")\n",
        "print(f\"   Test: {X_test_mtl_scaled.shape}\")\n",
        "print(f\"   Fraud balance: {np.bincount(y_train_f_mtl_balanced)}\\n\")\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_mtl_balanced).to(device)\n",
        "y_train_demand_tensor = torch.FloatTensor(y_train_d_mtl_balanced).to(device)\n",
        "y_train_fraud_tensor = torch.LongTensor(y_train_f_mtl_balanced).to(device)\n",
        "\n",
        "X_test_tensor = torch.FloatTensor(X_test_mtl_scaled).to(device)\n",
        "y_test_demand_tensor = torch.FloatTensor(y_test_d_mtl_scaled).to(device)\n",
        "y_test_fraud_tensor = torch.LongTensor(y_test_f_mtl).to(device)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_demand_tensor, y_train_fraud_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_demand_tensor, y_test_fraud_tensor)\n",
        "\n",
        "batch_size = 512\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# 6.3 TRAINING MTL MODEL - FIXED VERSION\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "print(\"üéØ Training Multi-Task Learning Model...\")\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X_train_mtl_balanced.shape[1]\n",
        "mtl_model = MultiTaskModel(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dims=[256, 128, 64],\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "# Loss functions\n",
        "criterion_demand = nn.MSELoss()\n",
        "criterion_fraud = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(mtl_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Learning rate scheduler - FIXED: removed verbose parameter\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 100\n",
        "best_loss = float('inf')\n",
        "patience = 15\n",
        "patience_counter = 0\n",
        "\n",
        "# Task weights\n",
        "lambda_demand = 1.0\n",
        "lambda_fraud = 1.0\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "print(f\"\\nüöÄ Starting MTL Training on {device}...\\n\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    mtl_model.train()\n",
        "    train_loss_epoch = 0\n",
        "    train_demand_loss_epoch = 0\n",
        "    train_fraud_loss_epoch = 0\n",
        "\n",
        "    for batch_X, batch_y_demand, batch_y_fraud in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        demand_pred, fraud_pred, _ = mtl_model(batch_X)\n",
        "\n",
        "        # Calculate losses\n",
        "        loss_demand = criterion_demand(demand_pred.squeeze(), batch_y_demand)\n",
        "        loss_fraud = criterion_fraud(fraud_pred, batch_y_fraud)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = lambda_demand * loss_demand + lambda_fraud * loss_fraud\n",
        "\n",
        "        # Backward pass\n",
        "        total_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(mtl_model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_epoch += total_loss.item()\n",
        "        train_demand_loss_epoch += loss_demand.item()\n",
        "        train_fraud_loss_epoch += loss_fraud.item()\n",
        "\n",
        "    # Validation phase\n",
        "    mtl_model.eval()\n",
        "    test_loss_epoch = 0\n",
        "    test_demand_loss_epoch = 0\n",
        "    test_fraud_loss_epoch = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y_demand, batch_y_fraud in test_loader:\n",
        "            demand_pred, fraud_pred, _ = mtl_model(batch_X)\n",
        "\n",
        "            loss_demand = criterion_demand(demand_pred.squeeze(), batch_y_demand)\n",
        "            loss_fraud = criterion_fraud(fraud_pred, batch_y_fraud)\n",
        "            total_loss = lambda_demand * loss_demand + lambda_fraud * loss_fraud\n",
        "\n",
        "            test_loss_epoch += total_loss.item()\n",
        "            test_demand_loss_epoch += loss_demand.item()\n",
        "            test_fraud_loss_epoch += loss_fraud.item()\n",
        "\n",
        "    # Calculate average losses\n",
        "    avg_train_loss = train_loss_epoch / len(train_loader)\n",
        "    avg_test_loss = test_loss_epoch / len(test_loader)\n",
        "\n",
        "    train_losses.append(avg_train_loss)\n",
        "    test_losses.append(avg_test_loss)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_test_loss)\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - LR: {current_lr:.6f}\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f} (Demand: {train_demand_loss_epoch/len(train_loader):.4f}, Fraud: {train_fraud_loss_epoch/len(train_loader):.4f})\")\n",
        "        print(f\"  Test Loss:  {avg_test_loss:.4f} (Demand: {test_demand_loss_epoch/len(test_loader):.4f}, Fraud: {test_fraud_loss_epoch/len(test_loader):.4f})\")\n",
        "\n",
        "    # Early stopping\n",
        "    if avg_test_loss < best_loss:\n",
        "        best_loss = avg_test_loss\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(mtl_model.state_dict(), 'best_mtl_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "print(f\"\\n‚úÖ Training completed!\")\n",
        "print(f\"   Best test loss: {best_loss:.4f}\\n\")\n",
        "\n",
        "# Load best model\n",
        "mtl_model.load_state_dict(torch.load('best_mtl_model.pth'))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6.4 EVALUATE MTL MODEL\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä Evaluating Multi-Task Learning Model...\\n\")\n",
        "\n",
        "mtl_model.eval()\n",
        "all_demand_preds = []\n",
        "all_fraud_preds = []\n",
        "all_fraud_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, _, _ in test_loader:\n",
        "        demand_pred, fraud_pred, _ = mtl_model(batch_X)\n",
        "        all_demand_preds.append(demand_pred.cpu().numpy())\n",
        "        all_fraud_preds.append(torch.argmax(fraud_pred, dim=1).cpu().numpy())\n",
        "        all_fraud_probs.append(F.softmax(fraud_pred, dim=1)[:, 1].cpu().numpy())\n",
        "\n",
        "# Concatenate predictions\n",
        "mtl_demand_preds = np.concatenate(all_demand_preds).flatten()\n",
        "mtl_fraud_preds = np.concatenate(all_fraud_preds)\n",
        "mtl_fraud_probs = np.concatenate(all_fraud_probs)\n",
        "\n",
        "# Inverse transform demand predictions\n",
        "mtl_demand_preds_original = demand_scaler.inverse_transform(mtl_demand_preds.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calculate metrics for demand forecasting\n",
        "mtl_rmse_demand = np.sqrt(mean_squared_error(y_test_d_mtl, mtl_demand_preds_original))\n",
        "mtl_mae_demand = mean_absolute_error(y_test_d_mtl, mtl_demand_preds_original)\n",
        "mtl_r2_demand = r2_score(y_test_d_mtl, mtl_demand_preds_original)\n",
        "mtl_mape_demand = np.mean(np.abs((y_test_d_mtl - mtl_demand_preds_original) / (y_test_d_mtl + 1))) * 100\n",
        "\n",
        "# Calculate metrics for fraud classification\n",
        "mtl_roc_auc = roc_auc_score(y_test_f_mtl, mtl_fraud_probs)\n",
        "mtl_avg_precision = average_precision_score(y_test_f_mtl, mtl_fraud_probs)\n",
        "mtl_f1 = f1_score(y_test_f_mtl, mtl_fraud_preds)\n",
        "mtl_accuracy = accuracy_score(y_test_f_mtl, mtl_fraud_preds)\n",
        "\n",
        "print(\"üéØ MULTI-TASK LEARNING RESULTS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìà TASK 1 - Demand Forecasting:\")\n",
        "print(f\"   RMSE: {mtl_rmse_demand:.4f}\")\n",
        "print(f\"   MAE: {mtl_mae_demand:.4f}\")\n",
        "print(f\"   R¬≤: {mtl_r2_demand:.4f}\")\n",
        "print(f\"   MAPE: {mtl_mape_demand:.4f}%\")\n",
        "\n",
        "print(\"\\nüîí TASK 2 - Fraud Detection:\")\n",
        "print(f\"   ROC-AUC: {mtl_roc_auc:.4f}\")\n",
        "print(f\"   Avg Precision: {mtl_avg_precision:.4f}\")\n",
        "print(f\"   F1-Score: {mtl_f1:.4f}\")\n",
        "print(f\"   Accuracy: {mtl_accuracy:.4f}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Add MTL results to comparison\n",
        "demand_results['MTL Model'] = {\n",
        "    'RMSE': mtl_rmse_demand,\n",
        "    'MAE': mtl_mae_demand,\n",
        "    'R2': mtl_r2_demand,\n",
        "    'MAPE': mtl_mape_demand\n",
        "}\n",
        "\n",
        "fraud_results['MTL Model'] = {\n",
        "    'ROC-AUC': mtl_roc_auc,\n",
        "    'Avg Precision': mtl_avg_precision,\n",
        "    'F1-Score': mtl_f1,\n",
        "    'Accuracy': mtl_accuracy\n",
        "}\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6.5 COMPARATIVE ANALYSIS: MTL vs Single-Task\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä COMPARATIVE ANALYSIS: MTL vs Single-Task Models\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüéØ DEMAND FORECASTING COMPARISON:\")\n",
        "demand_comparison = pd.DataFrame(demand_results).T\n",
        "demand_comparison = demand_comparison.sort_values('RMSE')\n",
        "print(demand_comparison.to_string())\n",
        "\n",
        "improvement_demand = ((demand_comparison.loc['XGBoost', 'RMSE'] -\n",
        "                       demand_comparison.loc['MTL Model', 'RMSE']) /\n",
        "                      demand_comparison.loc['XGBoost', 'RMSE'] * 100)\n",
        "print(f\"\\nüí° MTL Improvement over best single-task (XGBoost): {improvement_demand:.2f}%\")\n",
        "\n",
        "print(\"\\nüîí FRAUD DETECTION COMPARISON:\")\n",
        "fraud_comparison = pd.DataFrame(fraud_results).T\n",
        "fraud_comparison = fraud_comparison.sort_values('ROC-AUC', ascending=False)\n",
        "print(fraud_comparison.to_string())\n",
        "\n",
        "improvement_fraud = ((fraud_comparison.loc['MTL Model', 'ROC-AUC'] -\n",
        "                     fraud_comparison.loc['XGBoost', 'ROC-AUC']) /\n",
        "                    fraud_comparison.loc['XGBoost', 'ROC-AUC'] * 100)\n",
        "print(f\"\\nüí° MTL Improvement over best single-task (XGBoost): {improvement_fraud:.2f}%\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 7: TASK 3 - FRAUD ARCHETYPE DISCOVERY (UNSUPERVISED)\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç PHASE 7: FRAUD ARCHETYPE DISCOVERY (UNSUPERVISED CLUSTERING)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7.1 PREPARE FRAUD-RELATED FEATURES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üì¶ Preparing Fraud-Related Features for Clustering...\")\n",
        "\n",
        "# Select high-risk orders (top 30%)\n",
        "fraud_threshold_clustering = df_model['Fraud_Risk_Proxy_Score'].quantile(0.70)\n",
        "df_fraud_cluster = df_model[df_model['Fraud_Risk_Proxy_Score'] > fraud_threshold_clustering].copy()\n",
        "\n",
        "print(f\"‚úÖ Selected {len(df_fraud_cluster)} high-risk orders for clustering\")\n",
        "\n",
        "# Key fraud-related features\n",
        "fraud_features_for_clustering = [\n",
        "    'Order Item Discount Rate', 'Price_Per_Unit', 'Order Item Quantity',\n",
        "    'Payment_Risk_Score', 'Shipping_Risk_Score', 'Is_Cross_Border',\n",
        "    'High_Discount_Flag', 'Extreme_Discount_Flag',\n",
        "    'Cash_High_Discount', 'Cash_Cross_Border', 'Rush_Shipping_High_Discount',\n",
        "    'Customer_Fraud_Rate', 'Product_Fraud_Rate', 'Region_Fraud_Rate',\n",
        "    'Fraud_Risk_Proxy_Score'\n",
        "]\n",
        "\n",
        "X_fraud_cluster = df_fraud_cluster[fraud_features_for_clustering].values\n",
        "\n",
        "# Scale features\n",
        "scaler_cluster = StandardScaler()\n",
        "X_fraud_cluster_scaled = scaler_cluster.fit_transform(X_fraud_cluster)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7.2 DETERMINE OPTIMAL NUMBER OF CLUSTERS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üîç Finding Optimal Number of Clusters...\")\n",
        "\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "calinski_scores = []\n",
        "davies_bouldin_scores = []\n",
        "\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_fraud_cluster_scaled)\n",
        "\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_fraud_cluster_scaled, labels))\n",
        "    calinski_scores.append(calinski_harabasz_score(X_fraud_cluster_scaled, labels))\n",
        "    davies_bouldin_scores.append(davies_bouldin_score(X_fraud_cluster_scaled, labels))\n",
        "\n",
        "# Find optimal k (highest silhouette score)\n",
        "optimal_k_idx = np.argmax(silhouette_scores)\n",
        "optimal_k = list(K_range)[optimal_k_idx]\n",
        "\n",
        "print(f\"\\n‚úÖ Optimal number of clusters: {optimal_k}\")\n",
        "print(f\"   Silhouette Score: {silhouette_scores[optimal_k_idx]:.4f}\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7.3 PERFORM CLUSTERING\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(f\"\\nüéØ Performing K-Means Clustering with k={optimal_k}...\")\n",
        "\n",
        "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
        "cluster_labels = kmeans_final.fit_predict(X_fraud_cluster_scaled)\n",
        "\n",
        "df_fraud_cluster['Cluster'] = cluster_labels\n",
        "\n",
        "print(f\"‚úÖ Clustering completed!\")\n",
        "print(f\"\\nCluster distribution:\")\n",
        "print(df_fraud_cluster['Cluster'].value_counts().sort_index())\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7.4 ANALYZE FRAUD ARCHETYPES\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\nüìä FRAUD ARCHETYPE ANALYSIS:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "archetype_profiles = {}\n",
        "\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = df_fraud_cluster[df_fraud_cluster['Cluster'] == cluster_id]\n",
        "\n",
        "    print(f\"\\nüî∏ ARCHETYPE {cluster_id + 1} (n={len(cluster_data)})\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Key characteristics\n",
        "    profile = {\n",
        "        'Size': len(cluster_data),\n",
        "        'Avg_Discount': cluster_data['Order Item Discount Rate'].mean(),\n",
        "        'Avg_Order_Value': cluster_data['Sales'].mean(),\n",
        "        'Avg_Quantity': cluster_data['Order Item Quantity'].mean(),\n",
        "        'Cross_Border_Rate': cluster_data['Is_Cross_Border'].mean(),\n",
        "        'High_Discount_Rate': cluster_data['High_Discount_Flag'].mean(),\n",
        "        'Cash_Payment_Rate': (cluster_data['Type_Encoded'] == label_encoders['Type'].transform(['CASH'])[0]).mean(),\n",
        "        'Rush_Shipping_Rate': (cluster_data['Shipping Mode_Encoded'] ==\n",
        "                               label_encoders['Shipping Mode'].transform(['Same Day'])[0]).mean(),\n",
        "        'Avg_Risk_Score': cluster_data['Fraud_Risk_Proxy_Score'].mean()\n",
        "    }\n",
        "\n",
        "    archetype_profiles[f'Archetype_{cluster_id + 1}'] = profile\n",
        "\n",
        "    # Print profile\n",
        "    print(f\"  Average Discount Rate: {profile['Avg_Discount']*100:.2f}%\")\n",
        "    print(f\"  Average Order Value: ${profile['Avg_Order_Value']:.2f}\")\n",
        "    print(f\"  Average Quantity: {profile['Avg_Quantity']:.2f}\")\n",
        "    print(f\"  Cross-Border Rate: {profile['Cross_Border_Rate']*100:.2f}%\")\n",
        "    print(f\"  High Discount Rate: {profile['High_Discount_Rate']*100:.2f}%\")\n",
        "    print(f\"  Cash Payment Rate: {profile['Cash_Payment_Rate']*100:.2f}%\")\n",
        "    print(f\"  Rush Shipping Rate: {profile['Rush_Shipping_Rate']*100:.2f}%\")\n",
        "    print(f\"  Average Risk Score: {profile['Avg_Risk_Score']:.2f}\")\n",
        "\n",
        "    # Most common characteristics\n",
        "    print(f\"\\n  Top Payment Types:\")\n",
        "    print(cluster_data['Type'].value_counts().head(3).to_string())\n",
        "\n",
        "    print(f\"\\n  Top Regions:\")\n",
        "    print(cluster_data['Order Region'].value_counts().head(3).to_string())\n",
        "\n",
        "    print(f\"\\n  Top Categories:\")\n",
        "    print(cluster_data['Category Name'].value_counts().head(3).to_string())\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7.5 DIMENSIONALITY REDUCTION FOR VISUALIZATION\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\nüé® Performing Dimensionality Reduction...\")\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_fraud_cluster_scaled)\n",
        "\n",
        "print(f\"‚úÖ PCA completed\")\n",
        "print(f\"   Explained variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
        "\n",
        "# t-SNE (sample if too large)\n",
        "if len(X_fraud_cluster_scaled) > 5000:\n",
        "    sample_idx = np.random.choice(len(X_fraud_cluster_scaled), 5000, replace=False)\n",
        "    X_tsne_input = X_fraud_cluster_scaled[sample_idx]\n",
        "    tsne_labels = cluster_labels[sample_idx]\n",
        "else:\n",
        "    X_tsne_input = X_fraud_cluster_scaled\n",
        "    tsne_labels = cluster_labels\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "X_tsne = tsne.fit_transform(X_tsne_input)\n",
        "\n",
        "print(f\"‚úÖ t-SNE completed\")\n",
        "\n",
        "# Store for visualization later\n",
        "clustering_results = {\n",
        "    'pca_coords': X_pca,\n",
        "    'tsne_coords': X_tsne,\n",
        "    'cluster_labels': cluster_labels,\n",
        "    'tsne_labels': tsne_labels,\n",
        "    'archetype_profiles': archetype_profiles\n",
        "}\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 8: EXPLAINABILITY WITH SHAP\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ PHASE 8: MODEL EXPLAINABILITY WITH SHAP\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 8.1 SHAP FOR DEMAND FORECASTING (XGBoost)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä Computing SHAP Values for Demand Forecasting Model...\")\n",
        "\n",
        "# Sample data for faster computation\n",
        "sample_size_shap = min(5000, len(X_test_d))\n",
        "sample_idx_demand = np.random.choice(len(X_test_d), sample_size_shap, replace=False)\n",
        "X_shap_demand = X_test_d[sample_idx_demand]\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer_demand = shap.TreeExplainer(xgb_demand)\n",
        "shap_values_demand = explainer_demand.shap_values(X_shap_demand)\n",
        "\n",
        "print(f\"‚úÖ SHAP values computed for demand forecasting\")\n",
        "\n",
        "# Feature importance from SHAP\n",
        "shap_importance_demand = np.abs(shap_values_demand).mean(axis=0)\n",
        "feature_importance_demand = pd.DataFrame({\n",
        "    'Feature': [all_features[i] for i in range(len(all_features))],\n",
        "    'SHAP_Importance': shap_importance_demand\n",
        "}).sort_values('SHAP_Importance', ascending=False)\n",
        "\n",
        "print(\"\\nüîù Top 15 Features for Demand Forecasting:\")\n",
        "print(feature_importance_demand.head(15).to_string(index=False))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 8.2 SHAP FOR FRAUD DETECTION (XGBoost)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\nüîí Computing SHAP Values for Fraud Detection Model...\")\n",
        "\n",
        "sample_idx_fraud = np.random.choice(len(X_test_f), sample_size_shap, replace=False)\n",
        "X_shap_fraud = X_test_f[sample_idx_fraud]\n",
        "\n",
        "explainer_fraud = shap.TreeExplainer(xgb_fraud)\n",
        "shap_values_fraud = explainer_fraud.shap_values(X_shap_fraud)\n",
        "\n",
        "print(f\"‚úÖ SHAP values computed for fraud detection\")\n",
        "\n",
        "# Feature importance from SHAP\n",
        "if isinstance(shap_values_fraud, list):\n",
        "    shap_values_fraud_class1 = shap_values_fraud[1]\n",
        "else:\n",
        "    shap_values_fraud_class1 = shap_values_fraud\n",
        "\n",
        "shap_importance_fraud = np.abs(shap_values_fraud_class1).mean(axis=0)\n",
        "feature_importance_fraud = pd.DataFrame({\n",
        "    'Feature': [all_features[i] for i in range(len(all_features))],\n",
        "    'SHAP_Importance': shap_importance_fraud\n",
        "}).sort_values('SHAP_Importance', ascending=False)\n",
        "\n",
        "print(\"\\nüîù Top 15 Features for Fraud Detection:\")\n",
        "print(feature_importance_fraud.head(15).to_string(index=False))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 8.3 KEY INSIGHTS FROM SHAP\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° KEY INSIGHTS FROM EXPLAINABILITY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find overlapping important features\n",
        "top_demand_features = set(feature_importance_demand.head(20)['Feature'])\n",
        "top_fraud_features = set(feature_importance_fraud.head(20)['Feature'])\n",
        "shared_important_features = top_demand_features.intersection(top_fraud_features)\n",
        "\n",
        "print(f\"\\nüîó Shared Important Features (appear in top 20 for both tasks):\")\n",
        "for feat in shared_important_features:\n",
        "    demand_rank = feature_importance_demand[feature_importance_demand['Feature'] == feat].index[0] + 1\n",
        "    fraud_rank = feature_importance_fraud[feature_importance_fraud['Feature'] == feat].index[0] + 1\n",
        "    print(f\"  ‚Ä¢ {feat}\")\n",
        "    print(f\"    - Demand rank: #{demand_rank}, Fraud rank: #{fraud_rank}\")\n",
        "\n",
        "print(f\"\\nüìà Business Implications:\")\n",
        "print(\"  ‚Ä¢ Discount rate is critical for BOTH demand forecasting and fraud detection\")\n",
        "print(\"  ‚Ä¢ Regional patterns influence both legitimate demand and fraud risk\")\n",
        "print(\"  ‚Ä¢ Payment types serve as strong fraud indicators but less impact on demand\")\n",
        "print(\"  ‚Ä¢ Customer behavior aggregations help identify both trends and anomalies\")\n",
        "\n",
        "# Store SHAP results\n",
        "shap_results = {\n",
        "    'demand_shap_values': shap_values_demand,\n",
        "    'fraud_shap_values': shap_values_fraud_class1,\n",
        "    'X_shap_demand': X_shap_demand,\n",
        "    'X_shap_fraud': X_shap_fraud,\n",
        "    'feature_importance_demand': feature_importance_demand,\n",
        "    'feature_importance_fraud': feature_importance_fraud,\n",
        "    'shared_features': list(shared_important_features)\n",
        "}\n",
        "\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# PHASE 9: SAVE RESULTS & MODELS\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üíæ PHASE 9: SAVING RESULTS & MODELS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create results directory\n",
        "import os\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 9.1 SAVE PERFORMANCE METRICS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìä Saving Performance Metrics...\")\n",
        "\n",
        "# Demand forecasting results\n",
        "demand_comparison.to_csv('results/demand_forecasting_results.csv')\n",
        "\n",
        "# Fraud detection results\n",
        "fraud_comparison.to_csv('results/fraud_detection_results.csv')\n",
        "\n",
        "# Archetype profiles\n",
        "pd.DataFrame(archetype_profiles).T.to_csv('results/fraud_archetype_profiles.csv')\n",
        "\n",
        "# Feature importance\n",
        "feature_importance_demand.to_csv('results/feature_importance_demand.csv', index=False)\n",
        "feature_importance_fraud.to_csv('results/feature_importance_fraud.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ Performance metrics saved\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 9.2 SAVE MODELS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"ü§ñ Saving Trained Models...\")\n",
        "\n",
        "# Save tree-based models\n",
        "pickle.dump(xgb_demand, open('results/xgb_demand_model.pkl', 'wb'))\n",
        "pickle.dump(xgb_fraud, open('results/xgb_fraud_model.pkl', 'wb'))\n",
        "pickle.dump(lgb_demand, open('results/lgb_demand_model.pkl', 'wb'))\n",
        "pickle.dump(rf_demand, open('results/rf_demand_model.pkl', 'wb'))\n",
        "pickle.dump(rf_fraud, open('results/rf_fraud_model.pkl', 'wb'))\n",
        "\n",
        "# Save scalers\n",
        "pickle.dump(scaler_demand, open('results/scaler_demand.pkl', 'wb'))\n",
        "pickle.dump(scaler_mtl, open('results/scaler_mtl.pkl', 'wb'))\n",
        "pickle.dump(demand_scaler, open('results/demand_target_scaler.pkl', 'wb'))\n",
        "\n",
        "# Save label encoders\n",
        "pickle.dump(label_encoders, open('results/label_encoders.pkl', 'wb'))\n",
        "\n",
        "print(\"‚úÖ Models saved\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 9.3 SAVE CLUSTERING RESULTS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üîç Saving Clustering Results...\")\n",
        "\n",
        "df_fraud_cluster[['Cluster'] + fraud_features_for_clustering].to_csv(\n",
        "    'results/fraud_clusters.csv', index=False\n",
        ")\n",
        "\n",
        "pickle.dump(clustering_results, open('results/clustering_results.pkl', 'wb'))\n",
        "pickle.dump(kmeans_final, open('results/kmeans_model.pkl', 'wb'))\n",
        "\n",
        "print(\"‚úÖ Clustering results saved\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 9.4 SAVE SHAP RESULTS\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üî¨ Saving SHAP Results...\")\n",
        "\n",
        "pickle.dump(shap_results, open('results/shap_results.pkl', 'wb'))\n",
        "\n",
        "print(\"‚úÖ SHAP results saved\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 9.5 CREATE SUMMARY REPORT\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"üìù Creating Summary Report...\")\n",
        "\n",
        "summary_report = {\n",
        "    'Project': 'Explainable Multi-Task Learning for Supply Chain',\n",
        "    'Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'Dataset_Shape': df.shape,\n",
        "    'Total_Features': len(all_features),\n",
        "    'Demand_Forecasting': {\n",
        "        'Best_Model': 'MTL Model' if mtl_rmse_demand < rmse_xgb else 'XGBoost',\n",
        "        'Best_RMSE': min(mtl_rmse_demand, rmse_xgb),\n",
        "        'Best_R2': max(mtl_r2_demand, r2_xgb),\n",
        "        'MTL_vs_XGBoost_Improvement': improvement_demand\n",
        "    },\n",
        "    'Fraud_Detection': {\n",
        "        'Best_Model': 'MTL Model' if mtl_roc_auc > roc_auc_xgb_f else 'XGBoost',\n",
        "        'Best_ROC_AUC': max(mtl_roc_auc, roc_auc_xgb_f),\n",
        "        'Best_F1': max(mtl_f1, f1_xgb_f),\n",
        "        'MTL_vs_XGBoost_Improvement': improvement_fraud\n",
        "    },\n",
        "    'Fraud_Archetypes': {\n",
        "        'Num_Clusters': optimal_k,\n",
        "        'Silhouette_Score': silhouette_scores[optimal_k_idx],\n",
        "        'High_Risk_Orders_Analyzed': len(df_fraud_cluster)\n",
        "    },\n",
        "    'Top_Shared_Features': list(shared_important_features)[:10]\n",
        "}\n",
        "\n",
        "with open('results/summary_report.json', 'w') as f:\n",
        "    json.dump(summary_report, f, indent=4)\n",
        "\n",
        "print(\"‚úÖ Summary report created\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ALL RESULTS SAVED TO 'results/' DIRECTORY\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"\\nüèÜ PROJECT COMPLETE!\")\n",
        "print(\"\\nüìÅ OUTPUT FILES:\")\n",
        "print(\"  ‚Ä¢ results/demand_forecasting_results.csv\")\n",
        "print(\"  ‚Ä¢ results/fraud_detection_results.csv\")\n",
        "print(\"  ‚Ä¢ results/fraud_archetype_profiles.csv\")\n",
        "print(\"  ‚Ä¢ results/feature_importance_demand.csv\")\n",
        "print(\"  ‚Ä¢ results/feature_importance_fraud.csv\")\n",
        "print(\"  ‚Ä¢ results/summary_report.json\")\n",
        "print(\"  ‚Ä¢ results/*.pkl (models and data)\")\n",
        "print(\"  ‚Ä¢ best_mtl_model.pth (PyTorch MTL model)\")\n",
        "\n",
        "print(\"\\n‚ú® Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi ƒë·ªì √°n! ‚ú®\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# VISUALIZATION: 2 KEY FIGURES FOR LATEX REPORT\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (16, 8)\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# FIGURE 1: MULTI-TASK LEARNING ARCHITECTURE & PERFORMANCE COMPARISON\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "fig1 = plt.figure(figsize=(18, 8))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# LEFT: MTL Architecture Diagram\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "ax1.axis('off')\n",
        "\n",
        "# Architecture components\n",
        "layer_y = [0.9, 0.7, 0.5, 0.3, 0.15, 0.0]\n",
        "layer_labels = ['Input Features\\n(69 features)',\n",
        "                'Shared Layer 1\\n(256 units)',\n",
        "                'Shared Layer 2\\n(128 units)',\n",
        "                'Shared Layer 3\\n(64 units)',\n",
        "                'Task-Specific Heads',\n",
        "                'Outputs']\n",
        "\n",
        "colors_arch = ['#E8F4F8', '#B3E5FC', '#81D4FA', '#4FC3F7', '#FFE082', '#C8E6C9']\n",
        "\n",
        "# Draw architecture\n",
        "for i, (y, label, color) in enumerate(zip(layer_y, layer_labels, colors_arch)):\n",
        "    if i < 4:  # Shared layers\n",
        "        rect = plt.Rectangle((0.1, y-0.05), 0.8, 0.08,\n",
        "                             facecolor=color, edgecolor='black', linewidth=2)\n",
        "        ax1.add_patch(rect)\n",
        "        ax1.text(0.5, y, label, ha='center', va='center',\n",
        "                fontsize=11, fontweight='bold')\n",
        "    elif i == 4:  # Task heads\n",
        "        # Demand head\n",
        "        rect1 = plt.Rectangle((0.05, y-0.05), 0.35, 0.08,\n",
        "                              facecolor=colors_arch[4], edgecolor='black', linewidth=2)\n",
        "        ax1.add_patch(rect1)\n",
        "        ax1.text(0.225, y, 'Demand Head\\n(Regression)', ha='center', va='center',\n",
        "                fontsize=10, fontweight='bold')\n",
        "\n",
        "        # Fraud head\n",
        "        rect2 = plt.Rectangle((0.6, y-0.05), 0.35, 0.08,\n",
        "                              facecolor=colors_arch[5], edgecolor='black', linewidth=2)\n",
        "        ax1.add_patch(rect2)\n",
        "        ax1.text(0.775, y, 'Fraud Head\\n(Classification)', ha='center', va='center',\n",
        "                fontsize=10, fontweight='bold')\n",
        "    else:  # Outputs\n",
        "        # Demand output\n",
        "        ax1.text(0.225, y, 'Monthly\\nDemand', ha='center', va='center',\n",
        "                fontsize=10, style='italic', color='#F57C00')\n",
        "        # Fraud output\n",
        "        ax1.text(0.775, y, 'Fraud Risk\\nScore', ha='center', va='center',\n",
        "                fontsize=10, style='italic', color='#388E3C')\n",
        "\n",
        "# Arrows\n",
        "arrow_props = dict(arrowstyle='->', lw=2, color='gray')\n",
        "for i in range(len(layer_y)-2):\n",
        "    if i < 3:  # Shared layers arrows\n",
        "        ax1.annotate('', xy=(0.5, layer_y[i+1]+0.03), xytext=(0.5, layer_y[i]-0.03),\n",
        "                    arrowprops=arrow_props)\n",
        "    elif i == 3:  # Split to task heads\n",
        "        ax1.annotate('', xy=(0.225, layer_y[i+1]+0.03), xytext=(0.4, layer_y[i]-0.03),\n",
        "                    arrowprops=arrow_props)\n",
        "        ax1.annotate('', xy=(0.775, layer_y[i+1]+0.03), xytext=(0.6, layer_y[i]-0.03),\n",
        "                    arrowprops=arrow_props)\n",
        "    else:  # To outputs\n",
        "        ax1.annotate('', xy=(0.225, layer_y[i+1]+0.02), xytext=(0.225, layer_y[i]-0.03),\n",
        "                    arrowprops=arrow_props)\n",
        "        ax1.annotate('', xy=(0.775, layer_y[i+1]+0.02), xytext=(0.775, layer_y[i]-0.03),\n",
        "                    arrowprops=arrow_props)\n",
        "\n",
        "ax1.set_xlim(0, 1)\n",
        "ax1.set_ylim(-0.05, 1)\n",
        "ax1.set_title('(A) Multi-Task Learning Architecture', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# MIDDLE: Demand Forecasting Performance Comparison\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "\n",
        "# Load results\n",
        "demand_results = pd.read_csv('results/demand_forecasting_results.csv', index_col=0)\n",
        "\n",
        "models = demand_results.index.tolist()\n",
        "rmse_values = demand_results['RMSE'].values\n",
        "r2_values = demand_results['R2'].values\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "# Create bars\n",
        "bars1 = ax2.bar(x - width/2, rmse_values, width, label='RMSE ‚Üì',\n",
        "                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
        "bars2_ax = ax2.twinx()\n",
        "bars2 = bars2_ax.bar(x + width/2, r2_values, width, label='R¬≤ ‚Üë',\n",
        "                     color=['#95E1D3', '#F38181', '#AA96DA', '#FCBAD3'])\n",
        "\n",
        "# Customize\n",
        "ax2.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('RMSE (Lower is Better)', fontsize=11, fontweight='bold', color='#FF6B6B')\n",
        "bars2_ax.set_ylabel('R¬≤ Score (Higher is Better)', fontsize=11, fontweight='bold', color='#95E1D3')\n",
        "ax2.set_title('(B) Demand Forecasting Performance', fontsize=14, fontweight='bold', pad=20)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(models, rotation=15, ha='right')\n",
        "ax2.tick_params(axis='y', labelcolor='#FF6B6B')\n",
        "bars2_ax.tick_params(axis='y', labelcolor='#95E1D3')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    bars2_ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                 f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "# Legends\n",
        "ax2.legend(loc='upper left', fontsize=10)\n",
        "bars2_ax.legend(loc='upper right', fontsize=10)\n",
        "\n",
        "# Highlight best model\n",
        "best_idx = rmse_values.argmin()\n",
        "ax2.axvspan(best_idx - 0.4, best_idx + 0.4, alpha=0.2, color='gold')\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# RIGHT: Fraud Detection Performance Comparison\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax3 = plt.subplot(1, 3, 3)\n",
        "\n",
        "# Load results\n",
        "fraud_results = pd.read_csv('results/fraud_detection_results.csv', index_col=0)\n",
        "\n",
        "models_fraud = fraud_results.index.tolist()\n",
        "roc_auc = fraud_results['ROC-AUC'].values\n",
        "f1_score = fraud_results['F1-Score'].values\n",
        "\n",
        "x_fraud = np.arange(len(models_fraud))\n",
        "\n",
        "# Create grouped bars\n",
        "bars3 = ax3.bar(x_fraud - width/2, roc_auc, width, label='ROC-AUC',\n",
        "                color=['#667BC6', '#DA7297', '#FADA7A', '#82CD47'])\n",
        "bars4 = ax3.bar(x_fraud + width/2, f1_score, width, label='F1-Score',\n",
        "                color=['#C1ADEB', '#FFC7ED', '#FFE5B4', '#BFFCC6'])\n",
        "\n",
        "# Customize\n",
        "ax3.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Score (Higher is Better)', fontsize=11, fontweight='bold')\n",
        "ax3.set_title('(C) Fraud Detection Performance', fontsize=14, fontweight='bold', pad=20)\n",
        "ax3.set_xticks(x_fraud)\n",
        "ax3.set_xticklabels(models_fraud, rotation=15, ha='right')\n",
        "ax3.set_ylim([0.98, 1.002])\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "ax3.legend(loc='lower right', fontsize=10)\n",
        "\n",
        "# Add value labels\n",
        "for bars in [bars3, bars4]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.4f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
        "\n",
        "# Add perfect score line\n",
        "ax3.axhline(y=1.0, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Perfect Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/figure1_mtl_architecture_performance.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n",
        "print(\"‚úÖ Figure 1 saved: results/figure1_mtl_architecture_performance.png\")\n",
        "plt.close()\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# FIGURE 2: FRAUD ARCHETYPE DISCOVERY & SHAP EXPLAINABILITY\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "fig2 = plt.figure(figsize=(18, 8))\n",
        "\n",
        "# Load data\n",
        "clustering_results = pickle.load(open('results/clustering_results.pkl', 'rb'))\n",
        "shap_results = pickle.load(open('results/shap_results.pkl', 'rb'))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# LEFT: Fraud Archetypes (PCA Visualization)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax4 = plt.subplot(1, 3, 1)\n",
        "\n",
        "pca_coords = clustering_results['pca_coords']\n",
        "cluster_labels = clustering_results['cluster_labels']\n",
        "archetype_profiles = clustering_results['archetype_profiles']\n",
        "\n",
        "# Plot clusters\n",
        "scatter = ax4.scatter(pca_coords[:, 0], pca_coords[:, 1],\n",
        "                     c=cluster_labels, cmap='Set1',\n",
        "                     s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Add cluster centers\n",
        "for i in range(len(archetype_profiles)):\n",
        "    cluster_points = pca_coords[cluster_labels == i]\n",
        "    center = cluster_points.mean(axis=0)\n",
        "    ax4.scatter(center[0], center[1], c='black', s=300,\n",
        "               marker='*', edgecolors='yellow', linewidth=2, zorder=10)\n",
        "    ax4.text(center[0], center[1] - 0.5, f'Archetype {i+1}\\n(n={len(cluster_points)})',\n",
        "            ha='center', fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "ax4.set_xlabel('Principal Component 1', fontsize=11, fontweight='bold')\n",
        "ax4.set_ylabel('Principal Component 2', fontsize=11, fontweight='bold')\n",
        "ax4.set_title('(A) Fraud Archetype Clustering (PCA)', fontsize=14, fontweight='bold', pad=20)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.legend(*scatter.legend_elements(), title=\"Archetype\", loc='best', fontsize=9)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# MIDDLE: Archetype Profiles Heatmap\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax5 = plt.subplot(1, 3, 2)\n",
        "\n",
        "# Create profile comparison\n",
        "archetype_df = pd.DataFrame(archetype_profiles).T\n",
        "profile_features = ['Avg_Discount', 'Cross_Border_Rate', 'High_Discount_Rate',\n",
        "                   'Cash_Payment_Rate', 'Rush_Shipping_Rate', 'Avg_Risk_Score']\n",
        "archetype_subset = archetype_df[profile_features]\n",
        "\n",
        "# Normalize for better visualization\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_viz = MinMaxScaler()\n",
        "archetype_normalized = pd.DataFrame(\n",
        "    scaler_viz.fit_transform(archetype_subset.T).T,\n",
        "    columns=archetype_subset.columns,\n",
        "    index=archetype_subset.index\n",
        ")\n",
        "\n",
        "# Plot heatmap\n",
        "sns.heatmap(archetype_normalized.T, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
        "            cbar_kws={'label': 'Normalized Score'}, linewidths=2, linecolor='white',\n",
        "            ax=ax5, vmin=0, vmax=1)\n",
        "\n",
        "ax5.set_xlabel('Archetype', fontsize=11, fontweight='bold')\n",
        "ax5.set_ylabel('Fraud Characteristics', fontsize=11, fontweight='bold')\n",
        "ax5.set_title('(B) Archetype Profile Comparison', fontsize=14, fontweight='bold', pad=20)\n",
        "ax5.set_xticklabels(['Archetype 1\\n(Transfer/Debit)', 'Archetype 2\\n(Cash)'], rotation=0)\n",
        "ax5.set_yticklabels(['Avg Discount', 'Cross-Border', 'High Discount',\n",
        "                     'Cash Payment', 'Rush Shipping', 'Risk Score'], rotation=0)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# RIGHT: SHAP Feature Importance for Fraud Detection\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ax6 = plt.subplot(1, 3, 3)\n",
        "\n",
        "# Get top 10 features\n",
        "feature_importance_fraud = shap_results['feature_importance_fraud']\n",
        "top_features = feature_importance_fraud.head(10).copy()\n",
        "\n",
        "# Clean feature names\n",
        "feature_name_map = {\n",
        "    'Fraud_Risk_Proxy_Score': 'Fraud Risk\\nProxy',\n",
        "    'Order Item Discount Rate': 'Discount\\nRate',\n",
        "    'High_Discount_Flag': 'High Discount\\nFlag',\n",
        "    'Region_X_Payment_Risk': 'Region√óPayment\\nRisk',\n",
        "    'Payment_Risk_Score': 'Payment\\nRisk',\n",
        "    'Discount_X_Quantity': 'Discount√ó\\nQuantity',\n",
        "    'Days for shipment (scheduled)': 'Shipping\\nDays',\n",
        "    'Customer_Fraud_Rate': 'Customer\\nFraud Rate',\n",
        "    'Type_Encoded': 'Payment\\nType',\n",
        "    'Shipping_Risk_Score': 'Shipping\\nRisk'\n",
        "}\n",
        "\n",
        "top_features['Feature_Clean'] = top_features['Feature'].map(\n",
        "    lambda x: feature_name_map.get(x, x[:15])\n",
        ")\n",
        "\n",
        "# Create horizontal bar chart\n",
        "colors_shap = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
        "bars = ax6.barh(range(len(top_features)), top_features['SHAP_Importance'],\n",
        "                color=colors_shap, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "ax6.set_yticks(range(len(top_features)))\n",
        "ax6.set_yticklabels(top_features['Feature_Clean'][::-1], fontsize=10)\n",
        "ax6.set_xlabel('Mean |SHAP Value|', fontsize=11, fontweight='bold')\n",
        "ax6.set_title('(C) Top 10 Fraud Detection Features\\n(SHAP Importance)',\n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "ax6.grid(axis='x', alpha=0.3)\n",
        "ax6.invert_yaxis()\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, val) in enumerate(zip(bars, top_features['SHAP_Importance'])):\n",
        "    ax6.text(val, bar.get_y() + bar.get_height()/2, f'{val:.2f}',\n",
        "            va='center', ha='left', fontsize=9, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/figure2_fraud_archetypes_shap.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n",
        "print(\"‚úÖ Figure 2 saved: results/figure2_fraud_archetypes_shap.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üé® VISUALIZATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìä Generated 2 Key Figures:\")\n",
        "print(\"  1. figure1_mtl_architecture_performance.png\")\n",
        "print(\"     - MTL architecture diagram\")\n",
        "print(\"     - Demand forecasting comparison\")\n",
        "print(\"     - Fraud detection comparison\")\n",
        "print(\"\\n  2. figure2_fraud_archetypes_shap.png\")\n",
        "print(\"     - Fraud archetype clustering (PCA)\")\n",
        "print(\"     - Archetype profile heatmap\")\n",
        "print(\"     - SHAP feature importance\")\n",
        "print(\"\\n‚ú® Ready for LaTeX report insertion!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNYJ0CqcJXcb",
        "outputId": "340a8a10-04bb-4214-e673-d2daf48ee4d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Figure 1 saved: results/figure1_mtl_architecture_performance.png\n",
            "‚úÖ Figure 2 saved: results/figure2_fraud_archetypes_shap.png\n",
            "\n",
            "================================================================================\n",
            "üé® VISUALIZATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "üìä Generated 2 Key Figures:\n",
            "  1. figure1_mtl_architecture_performance.png\n",
            "     - MTL architecture diagram\n",
            "     - Demand forecasting comparison\n",
            "     - Fraud detection comparison\n",
            "\n",
            "  2. figure2_fraud_archetypes_shap.png\n",
            "     - Fraud archetype clustering (PCA)\n",
            "     - Archetype profile heatmap\n",
            "     - SHAP feature importance\n",
            "\n",
            "‚ú® Ready for LaTeX report insertion!\n"
          ]
        }
      ]
    }
  ]
}